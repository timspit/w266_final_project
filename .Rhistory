model1_confair = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level, data = results_armconfair) , clusters_in = NA)
#results_armconpur$recruitment_day = relevel(results_armconpur$recruitment_day, ref=3)
model1_conpure = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level+recruitment_day, data = results_armconpur), clusters_in = NA)
stargazer(model1_libfair$lm, model1_libpure$lm
, model1_confair$lm, model1_conpure$lm
, type = stargazer_type, header = F
, se = list(model1_libfair$se_robust, model1_libpure$se_robust
, model1_confair$se_robust, model1_conpure$se_robust)
, title = "Moral Foundations Prelim Regression Specifications"
, column.labels = c("Lib + Care", "Lib + Purity"
, "Con + Care", "Con + Purity")
, notes = "HC Robust Standard Errors"
, report = ('v*c*sp')
)
model1_libfair_gender = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level*gender + recruitment_day, data = results_armlibfair), clusters_in = NA)
model1_libpure_gender = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level*gender + recruitment_day, data = results_armlibpure), clusters_in = NA)
model1_confair_gender = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level*gender, data = results_armconfair) , clusters_in = NA)
model1_conpure_gender = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level*gender + recruitment_day, data = results_armconpur), clusters_in = NA)
stargazer(model1_libfair_gender$lm, model1_libpure_gender$lm
, model1_confair_gender$lm, model1_conpure_gender$lm
, type = stargazer_type, header = F
, se = list(model1_libfair_gender$se_robust, model1_libpure_gender$se_robust
, model1_confair_gender$se_robust, model1_conpure_gender$se_robust)
, title = "Moral Foundations Prelim Regression Specifications"
, column.labels = c("Lib + Care", "Lib + Purity"
, "Con + Care", "Con + Purity")
, notes = "HC Robust Standard Errors"
, report = ('v*c*sp')
)
model1_libfair_familiarity = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level*ubi_familiarity_bin, data = results_armlibfair), clusters_in = NA)
model1_libpure_familiarity = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level*ubi_familiarity_bin, data = results_armlibpure), clusters_in = NA)
model1_confair_familiarity = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level*ubi_familiarity_bin, data = results_armconfair) , clusters_in = NA)
model1_conpure_familiarity = my_lm_calcs(lm_in = lm(ubi_number ~ arm_level*ubi_familiarity_bin, data = results_armconpur), clusters_in = NA)
stargazer(model1_libfair_familiarity$lm, model1_libpure_familiarity$lm
, model1_confair_familiarity$lm, model1_conpure_familiarity$lm
, type = stargazer_type, header = F
, se = list(model1_libfair_familiarity$se_robust, model1_libpure_familiarity$se_robust
, model1_confair_familiarity$se_robust, model1_conpure_familiarity$se_robust)
, title = "Moral Foundations Prelim Regression Specifications"
, column.labels = c("Lib + Care", "Lib + Purity"
, "Con + Care", "Con + Purity")
, notes = "HC Robust Standard Errors"
, report = ('v*c*sp')
)
model2_conpure_base_reaction = my_lm_calcs(lm_in = lm(ubi_number ~ purity_q2_repulsed_bin
, data = results_armconpur %>% filter(arm_level != "extension")), clusters_in = NA)
model2_conpure_ext_reaction = my_lm_calcs(lm_in = lm(ubi_number ~ purity_q4_relieved_bin
, data = results_armconpur %>% filter(arm_level != "base")), clusters_in = NA)
stargazer(model2_conpure_base_reaction$lm, model2_conpure_ext_reaction$lm
, type = stargazer_type, header = F
, se = list(model2_conpure_base_reaction$se_robust, model2_conpure_ext_reaction$se_robust)
, title = "Moral Foundations Prelim Regression Specifications"
, column.labels = c("Con + Purity Base", "Con + Purity Ext")
, notes = "Bin 1 = None/A Little; Bin 2 = Everythign Positive"
, report = ('v*c*sp')
)
# Stargazer
install.packages(ong)
install.packages("png")
install.packages("grid")
install.packages("grid")
install.packages("grid")
install.packages("grid")
install.packages("grid")
library(openxlsx)
all_topics_errors_reviewed = read.xlsx("./final_outputs/all_topics_errors_reviewed.xlsx", sheet = "all_topics_errors")
View(all_topics_errors_reviewed)
# Confusion Plot
ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "green4") +
theme_bw() + theme(legend.position = "none") +
labs(x = "True Label", y = "Predicted Label") +
scale_y_discrete(limits = rev(label_levels)) +
scale_x_discrete(limits = rev(label_levels)) +
labs(title = "All Topics")
library(tidyverse)
library(gridExtra)
library(htmltools)
library(ggthemes)
library(RColorBrewer)
library(png)
library(grid)
library(openxlsx)
label_levels = c("Against", "None", "Favor")
# IMPORT
import_topic = function(topic_name){
tweet_data = read.csv(file = paste0("./final_outputs/", topic_name, "_tweets_v3.csv"), header = FALSE) %>%
# Check on why tweets have different index? probably maintain original whereas others are built from scratch
mutate(V1 = 1:n()-1)
pred_data = read.csv(file = paste0("./final_outputs/", topic_name, "_preds_v3.csv"), header = FALSE)
true_data = read.csv(file = paste0("./final_outputs/", topic_name, "_true_v3.csv"), header = FALSE)
names(pred_data) = c("obs_num", "predicted_label")
names(true_data) = c("obs_num", "true_label")
names(tweet_data) = c("obs_num", "tweet")
merged = tweet_data %>%
merge(pred_data
, by = "obs_num"
, all.x = TRUE) %>%
merge(true_data
, by = "obs_num"
, all.x = TRUE) %>%
mutate(topic = topic_name
, predicted_label_f = case_when(predicted_label == 0 ~ "Against"
, predicted_label == 1 ~ "None"
, predicted_label == 2 ~ "Favor"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
, true_label_f = case_when(true_label == 0 ~ "Against"
, true_label == 1 ~ "None"
, true_label == 2 ~ "Favor"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
)
return(merged)
}
abort = import_topic(topic_name = "abort")
atheism = import_topic(topic_name = "atheism")
clim = import_topic(topic_name = "clim")
hil = import_topic(topic_name = "hil")
fem = import_topic(topic_name = "fem")
all_topics = bind_rows(abort, atheism, clim, hil, fem)
# CALCULATE METRICS
metrics = function(y_true, y_pred){
confusion_matrix = as.matrix(table(Actual = y_true, Predicted = y_pred))
n = sum(confusion_matrix)
n_classes = nrow(confusion_matrix)
correct_byclass = diag(confusion_matrix)
instances_byclass = apply(confusion_matrix, 1, sum)
predictions_byclass = apply(confusion_matrix, 2, sum)
precision = correct_byclass / predictions_byclass
recall = correct_byclass / instances_byclass
f1 = 2 * precision * recall / (precision + recall)
classification_report = data.frame("Class" = label_levels
, "Precision" = round(precision * 100, 2)
, "Recall" = round(recall * 100, 2)
, "F1 Score" = round(f1 * 100, 2))
f1_macro = mean(f1)
f1_macro_custom = mean(f1[c(1,3)])
metric_list = list()
metric_list$confusion_matrix = confusion_matrix
metric_list$classification_report = classification_report
metric_list$f1_macro = f1_macro
metric_list$f1_macro_custom = f1_macro_custom
return(metric_list)
}
abort_metrics = metrics(y_true = abort$true_label_f, y_pred = abort$predicted_label_f)
atheism_metrics = metrics(y_true = atheism$true_label_f, y_pred = atheism$predicted_label_f)
clim_metrics = metrics(y_true = clim$true_label_f, y_pred = clim$predicted_label_f)
hil_metrics = metrics(y_true = hil$true_label_f, y_pred = hil$predicted_label_f)
fem_metrics = metrics(y_true = fem$true_label_f, y_pred = fem$predicted_label_f)
all_topics_metrics = metrics(y_true = all_topics$true_label_f, y_pred = all_topics$predicted_label_f)
# F stats
f_topics = c(atheism_metrics$f1_macro_custom
, clim_metrics$f1_macro_custom
, fem_metrics$f1_macro_custom
, hil_metrics$f1_macro_custom
, abort_metrics$f1_macro_custom)
f_summary = c(all_topics_metrics$f1_macro_custom
, mean(f_topics)
, f_topics)
f_summary = round(f_summary * 100, 2)
names(f_summary) = c("F-micro", "F-macro"
, "Atheism", "Climate Change", "Feminism", "Hillary Clinton", "Abortion")
# knitr::include_graphics(path = "images/bert_bytask.png")
bert_img = readPNG("images/bert_bytask.png")
grid.raster(bert_img)
grid.arrange(tableGrob(all_topics_metrics$classification_report %>% select(-Class))
, tableGrob(data.frame("F1 Score" = f_summary))
, nrow = 1)
measure_levels = c("F-micro", "F-macro", "Atheism", "Climate", "Feminism", "Hillary", "Abortion")
f_data = data.frame("measure" = c("F-micro", "F-macro", "Atheism", "Climate", "Feminism", "Hillary", "Abortion") %>%
factor(levels = measure_levels)
, "our_model" = f_summary
, "majority_classifer" = c(65.22,	40.092,	42.11,	42.12,	39.1,	36.83,	40.3)
) %>%
gather(key = "model", value = "value", -measure) %>%
mutate(custom_color = c(rep(1, 2), rep(3, 5)
, rep(2, 2), rep(4, 5)) %>% factor()) %>%
arrange(custom_color)
paired_palette = brewer.pal(n = 4, name = "Paired")
ggplot(data = f_data) +
geom_bar(aes(x = measure, y = value, fill = custom_color), colour = "black", stat = "identity", position = "dodge") +
scale_fill_manual(name = "Model"
, breaks = c(1, 2)
, labels = c("Dessouky/Spittle", "Majority Classifier")
, values = c(paired_palette[2], paired_palette[4], paired_palette[1], paired_palette[3])) +
labs(x = "Topic/Measure", y = "Score") +
theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust = 1)
, legend.position = "bottom")
# Confusion Plot
ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "green4") +
theme_bw() + theme(legend.position = "none") +
labs(x = "True Label", y = "Predicted Label") +
scale_y_discrete(limits = rev(label_levels)) +
scale_x_discrete(limits = rev(label_levels)) +
labs(title = "All Topics")
# Confusion Plot
ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "green4") +
theme_bw() + theme(legend.position = "none") +
labs(x = "True Label", y = "Predicted Label") +
scale_y_discrete(limits = rev(label_levels)) +
scale_x_discrete(limits = rev(label_levels)) +
labs(caption = "All Topics")
View(all_topics_errors_reviewed)
atheism_errors_annotated = all_topics_errors_reviewed %>%
filter(topic == "atheism")
View(atheism_errors_annotated)
atheism_errors_grouped = atheism_errors_annotated %>%
group_by(true_label_f, issue) %>%
summarise(count = n())
View(atheism_errors_grouped)
ggplot(data = atheism_errors_grouped) +
geom_bar(aes(x = true_label_f, y = count, fill = issue), position = "dodge", stat = "identity")
, aes(x = true_label_f, y = count, fill = issue)) +
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity")
, aes(x = true_label_f, y = count, fill = issue)) +
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity") +
theme_bw()
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
theme_bw()
knitr::include_graphics(path = "images/Dessouky_Spittle_Model_Diagram.JPG")
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
theme_bw()
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
theme_bw()
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
theme_bw() +
labs(x = "True Label", y = "Count", legend.tital = "Issue")
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
theme_bw() +
labs(x = "True Label", y = "Count", legend.title = "Issue")
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
labs(x = "True Label", y = "Count", legend.title = "Issue") +
theme_bw()
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
labs(x = "True Label", y = "Count") +
scale_fill_discrete(name = "Issue") +
theme_bw() + theme(legend.position = "bottom")
##################### Use below if needed to export raw errors again #####################
# all_topics_errors = all_topics %>%
#   filter(predicted_label != true_label) %>%
#   select(obs_num, topic, tweet, predicted_label_f, true_label_f)
#
# write.csv(all_topics_errors, file = "./final_outputs/all_topics_errors.csv")
##########################################################################################
all_topics_errors_reviewed = read.xlsx("./final_outputs/all_topics_errors_reviewed.xlsx", sheet = "all_topics_errors")
atheism_errors_annotated = all_topics_errors_reviewed %>%
filter(topic == "atheism")
atheism_errors_grouped = atheism_errors_annotated %>%
group_by(true_label_f, issue) %>%
summarise(count = n())
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
labs(x = "True Label", y = "Count") +
scale_fill_discrete(name = "Issue") +
theme_bw() + theme(legend.position = "bottom")
all_topics_errors = all_topics %>%
filter(predicted_label != true_label) %>%
select(obs_num, topic, tweet, predicted_label_f, true_label_f)
##################### Use below if needed to export raw errors again #####################
# write.csv(all_topics_errors, file = "./final_outputs/all_topics_errors.csv")
##########################################################################################
all_topics_errors_reviewed = read.xlsx("./final_outputs/all_topics_errors_reviewed.xlsx", sheet = "all_topics_errors")
atheism_errors_annotated = all_topics_errors_reviewed %>%
filter(topic == "atheism")
atheism_errors_grouped = atheism_errors_annotated %>%
group_by(true_label_f, issue) %>%
summarise(count = n())
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
labs(x = "True Label", y = "Count") +
scale_fill_discrete(name = "Issue") +
theme_bw() + theme(legend.position = "bottom")
atheism_errors_annotated %>% filter(topic == "atheism" & examples == "blatant") %>% select(tweet)
target_table = data.frame("Target" = c("Atheism", "Climate Change is a Real Concern", "Feminist Movement", "Hillary Clinton", "Legalization of Abortion")
, "Favor" = c("#NoMoreReligions", "-", "#INeedFeminismBecause", "#GoHillary", "#ProChoice_")
, "Against"= c("#GodsWill", "#GlobalWarmingHoax", "#FeminismIsAwful", "#WhyIAmNotVotingForHillary", "#PrayToEndAbortion")
, "Ambiguous" = c("#Atheism", "#ClimateChange", "#Feminism", "#Hillary2016", "#PlannedParenthood")
)
kable(target_table, "latex", booktabs = T) %>%
kable_styling(latex_options = "striped")
library(knitr)
library(kableExtra)
target_table = data.frame("Target" = c("Atheism", "Climate Change is a Real Concern", "Feminist Movement", "Hillary Clinton", "Legalization of Abortion")
, "Favor" = c("#NoMoreReligions", "-", "#INeedFeminismBecause", "#GoHillary", "#ProChoice_")
, "Against"= c("#GodsWill", "#GlobalWarmingHoax", "#FeminismIsAwful", "#WhyIAmNotVotingForHillary", "#PrayToEndAbortion")
, "Ambiguous" = c("#Atheism", "#ClimateChange", "#Feminism", "#Hillary2016", "#PlannedParenthood")
)
kable(target_table, "latex", booktabs = T) %>%
kable_styling(latex_options = "striped")
target_table = data.frame("Target" = c("Atheism", "Climate Change is a Real Concern", "Feminist Movement", "Hillary Clinton", "Legalization of Abortion")
, "Favor" = c("#NoMoreReligions", "-", "#INeedFeminismBecause", "#GoHillary", "#ProChoice_")
, "Against"= c("#GodsWill", "#GlobalWarmingHoax", "#FeminismIsAwful", "#WhyIAmNotVotingForHillary", "#PrayToEndAbortion")
, "Ambiguous" = c("#Atheism", "#ClimateChange", "#Feminism", "#Hillary2016", "#PlannedParenthood")
)
kable(target_table, "latex", booktabs = T) %>%
kable_styling(latex_options = "striped")
target_table = data.frame("Target" = c("Atheism", "Climate Change is a Real Concern", "Feminist Movement", "Hillary Clinton", "Legalization of Abortion")
, "Favor" = c("#NoMoreReligions", "-", "#INeedFeminismBecause", "#GoHillary", "#ProChoice_")
, "Against"= c("#GodsWill", "#GlobalWarmingHoax", "#FeminismIsAwful", "#WhyIAmNotVotingForHillary", "#PrayToEndAbortion")
, "Ambiguous" = c("#Atheism", "#ClimateChange", "#Feminism", "#Hillary2016", "#PlannedParenthood")
)
kable(target_table, "latex", booktabs = T)
?kable
target_table = data.frame("Target" = c("Atheism", "Climate Change is a Real Concern", "Feminist Movement", "Hillary Clinton", "Legalization of Abortion")
, "Favor" = c("#NoMoreReligions", "-", "#INeedFeminismBecause", "#GoHillary", "#ProChoice_")
, "Against"= c("#GodsWill", "#GlobalWarmingHoax", "#FeminismIsAwful", "#WhyIAmNotVotingForHillary", "#PrayToEndAbortion")
, "Ambiguous" = c("#Atheism", "#ClimateChange", "#Feminism", "#Hillary2016", "#PlannedParenthood")
)
knitr::kable(target_table, "latex", booktabs = T)
View(target_table)
target_table = data.frame("Target" = c("Atheism", "Climate Change is a Real Concern", "Feminist Movement", "Hillary Clinton", "Legalization of Abortion")
, "Favor" = c("#NoMoreReligions", "none", "#INeedFeminismBecause", "#GoHillary", "#ProChoice")
, "Against"= c("#GodsWill", "#GlobalWarmingHoax", "#FeminismIsAwful", "#WhyIAmNotVotingForHillary", "#PrayToEndAbortion")
, "Ambiguous" = c("#Atheism", "#ClimateChange", "#Feminism", "#Hillary2016", "#PlannedParenthood")
)
knitr::kable(target_table, "latex", booktabs = T)
target_table = data.frame("Target" = c("Atheism", "Climate Change is a Real Concern", "Feminist Movement", "Hillary Clinton", "Legalization of Abortion")
, "Favor" = c("#NoMoreReligions", "none", "#INeedFeminismBecause", "#GoHillary", "#ProChoice")
, "Against"= c("#GodsWill", "#GlobalWarmingHoax", "#FeminismIsAwful", "#WhyIAmNotVotingForHillary", "#PrayToEndAbortion")
, "Ambiguous" = c("#Atheism", "#ClimateChange", "#Feminism", "#Hillary2016", "#PlannedParenthood")
)
knitr::kable(target_table)
all_topics_errors = all_topics %>%
filter(predicted_label != true_label) %>%
select(obs_num, topic, tweet, predicted_label_f, true_label_f)
library(tidyverse)
library(gridExtra)
library(htmltools)
library(ggthemes)
library(RColorBrewer)
library(png)
library(grid)
library(openxlsx)
library(knitr)
library(kableExtra)
label_levels = c("Against", "None", "Favor")
# IMPORT
import_topic = function(topic_name){
tweet_data = read.csv(file = paste0("./final_outputs/", topic_name, "_tweets_v3.csv"), header = FALSE) %>%
# Check on why tweets have different index? probably maintain original whereas others are built from scratch
mutate(V1 = 1:n()-1)
pred_data = read.csv(file = paste0("./final_outputs/", topic_name, "_preds_v3.csv"), header = FALSE)
true_data = read.csv(file = paste0("./final_outputs/", topic_name, "_true_v3.csv"), header = FALSE)
names(pred_data) = c("obs_num", "predicted_label")
names(true_data) = c("obs_num", "true_label")
names(tweet_data) = c("obs_num", "tweet")
merged = tweet_data %>%
merge(pred_data
, by = "obs_num"
, all.x = TRUE) %>%
merge(true_data
, by = "obs_num"
, all.x = TRUE) %>%
mutate(topic = topic_name
, predicted_label_f = case_when(predicted_label == 0 ~ "Against"
, predicted_label == 1 ~ "None"
, predicted_label == 2 ~ "Favor"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
, true_label_f = case_when(true_label == 0 ~ "Against"
, true_label == 1 ~ "None"
, true_label == 2 ~ "Favor"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
)
return(merged)
}
abort = import_topic(topic_name = "abort")
atheism = import_topic(topic_name = "atheism")
clim = import_topic(topic_name = "clim")
hil = import_topic(topic_name = "hil")
fem = import_topic(topic_name = "fem")
all_topics = bind_rows(abort, atheism, clim, hil, fem)
# CALCULATE METRICS
metrics = function(y_true, y_pred){
confusion_matrix = as.matrix(table(Actual = y_true, Predicted = y_pred))
n = sum(confusion_matrix)
n_classes = nrow(confusion_matrix)
correct_byclass = diag(confusion_matrix)
instances_byclass = apply(confusion_matrix, 1, sum)
predictions_byclass = apply(confusion_matrix, 2, sum)
precision = correct_byclass / predictions_byclass
recall = correct_byclass / instances_byclass
f1 = 2 * precision * recall / (precision + recall)
classification_report = data.frame("Class" = label_levels
, "Precision" = round(precision * 100, 2)
, "Recall" = round(recall * 100, 2)
, "F1 Score" = round(f1 * 100, 2))
f1_macro = mean(f1)
f1_macro_custom = mean(f1[c(1,3)])
metric_list = list()
metric_list$confusion_matrix = confusion_matrix
metric_list$classification_report = classification_report
metric_list$f1_macro = f1_macro
metric_list$f1_macro_custom = f1_macro_custom
return(metric_list)
}
abort_metrics = metrics(y_true = abort$true_label_f, y_pred = abort$predicted_label_f)
atheism_metrics = metrics(y_true = atheism$true_label_f, y_pred = atheism$predicted_label_f)
clim_metrics = metrics(y_true = clim$true_label_f, y_pred = clim$predicted_label_f)
hil_metrics = metrics(y_true = hil$true_label_f, y_pred = hil$predicted_label_f)
fem_metrics = metrics(y_true = fem$true_label_f, y_pred = fem$predicted_label_f)
all_topics_metrics = metrics(y_true = all_topics$true_label_f, y_pred = all_topics$predicted_label_f)
# F stats
f_topics = c(atheism_metrics$f1_macro_custom
, clim_metrics$f1_macro_custom
, fem_metrics$f1_macro_custom
, hil_metrics$f1_macro_custom
, abort_metrics$f1_macro_custom)
f_summary = c(all_topics_metrics$f1_macro_custom
, mean(f_topics)
, f_topics)
f_summary = round(f_summary * 100, 2)
names(f_summary) = c("F-micro", "F-macro"
, "Atheism", "Climate Change", "Feminism", "Hillary Clinton", "Abortion")
target_table = data.frame("Target" = c("Atheism", "Climate Change is a Real Concern", "Feminist Movement", "Hillary Clinton", "Legalization of Abortion")
, "Favor" = c("#NoMoreReligions", "none", "#INeedFeminismBecause", "#GoHillary", "#ProChoice")
, "Against"= c("#GodsWill", "#GlobalWarmingHoax", "#FeminismIsAwful", "#WhyIAmNotVotingForHillary", "#PrayToEndAbortion")
, "Ambiguous" = c("#Atheism", "#ClimateChange", "#Feminism", "#Hillary2016", "#PlannedParenthood")
)
knitr::kable(target_table)
# knitr::include_graphics(path = "images/bert_bytask.png")
bert_img = readPNG("images/bert_bytask.png")
grid.raster(bert_img)
knitr::include_graphics(path = "images/Dessouky_Spittle_Model_Diagram.JPG")
grid.arrange(tableGrob(all_topics_metrics$classification_report %>% select(-Class))
, tableGrob(data.frame("F1 Score" = f_summary))
, nrow = 1)
measure_levels = c("F-micro", "F-macro", "Atheism", "Climate", "Feminism", "Hillary", "Abortion")
f_data = data.frame("measure" = c("F-microT", "F-macroT", "Atheism", "Climate", "Feminism", "Hillary", "Abortion") %>%
factor(levels = measure_levels)
, "our_model" = f_summary
, "majority_classifer" = c(65.22,	40.092,	42.11,	42.12,	39.1,	36.83,	40.3)
) %>%
gather(key = "model", value = "value", -measure) %>%
mutate(custom_color = c(rep(1, 2), rep(3, 5)
, rep(2, 2), rep(4, 5)) %>% factor()) %>%
arrange(custom_color)
paired_palette = brewer.pal(n = 4, name = "Paired")
ggplot(data = f_data) +
geom_bar(aes(x = measure, y = value, fill = custom_color), colour = "black", stat = "identity", position = "dodge") +
scale_fill_manual(name = "Model"
, breaks = c(1, 2)
, labels = c("Dessouky/Spittle", "Majority Classifier")
, values = c(paired_palette[2], paired_palette[4], paired_palette[1], paired_palette[3])) +
labs(x = "Topic/Measure", y = "Score") +
theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust = 1)
, legend.position = "bottom")
# Confusion Plot
ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "green4") +
theme_bw() + theme(legend.position = "none") +
labs(x = "True Label", y = "Predicted Label") +
scale_y_discrete(limits = rev(label_levels)) +
scale_x_discrete(limits = rev(label_levels)) +
labs(caption = "Note: All Topics")
all_topics_errors = all_topics %>%
filter(predicted_label != true_label) %>%
select(obs_num, topic, tweet, predicted_label_f, true_label_f)
##################### Use below if needed to export raw errors again #####################
# write.csv(all_topics_errors, file = "./final_outputs/all_topics_errors.csv")
##########################################################################################
all_topics_errors_reviewed = read.xlsx("./final_outputs/all_topics_errors_reviewed.xlsx", sheet = "all_topics_errors")
atheism_errors_annotated = all_topics_errors_reviewed %>%
filter(topic == "atheism")
atheism_errors_grouped = atheism_errors_annotated %>%
group_by(true_label_f, issue) %>%
summarise(count = n())
ggplot(data = atheism_errors_grouped
, aes(x = true_label_f, y = count, fill = issue)) +
geom_bar(position = "stack", stat = "identity", color = "black") +
labs(x = "True Label", y = "Count") +
scale_fill_discrete(name = "Issue") +
theme_bw() + theme(legend.position = "bottom")
atheism_errors_annotated %>% filter(topic == "atheism" & examples == "blatant") %>% select(tweet) %?% gsub("@", "[AT]")
atheism_errors_annotated %>% filter(topic == "atheism" & examples == "blatant") %>% select(tweet) %>% gsub("@", "[AT]")
atheism_errors_annotated %>% filter(topic == "atheism" & examples == "blatant") %>% select(tweet)
atheism_errors_annotated %>% filter(topic == "atheism" & examples == "blatant") %>% select(tweet) %>% str_replace("@", "[AT]")
install.packages("tinytex")
knitr::kable(target_table)
options(tinytex.verbose = TRUE)
