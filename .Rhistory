abort_preds = read.csv("./final_outputs/abort_preds.csv")
View(abort_preds)
abort_true = read.csv("./final_outputs/abort_true.csv")
View(abort_true)
names(abort_preds) = c("obs_num", "predicted_label")
names(abort_true) = c("obs_num", "true_label")
abort = merge(abort_preds, abort_true, by = "obs_num")
View(abort)
import_topic = function(topic_name){
preds = read.csv(paste0("./final_outputs/", topic_name, "_preds.csv"))
true = read.csv(paste0("./final_outputs/", topic_name, "_true.csv"))
names(preds) = c("obs_num", "predicted_label")
names(true) = c("obs_num", "true_label")
merged = merge(preds, true, by = "obs_num")
}
abort = import_topic(topic_name = "abort")
library(tidyverse)
import_topic = function(topic_name){
preds = read.csv(paste0("./final_outputs/", topic_name, "_preds.csv"))
true = read.csv(paste0("./final_outputs/", topic_name, "_true.csv"))
names(preds) = c("obs_num", "predicted_label")
names(true) = c("obs_num", "true_label")
merged = merge(preds, true, by = "obs_num") %>%
mutate(topic = topic_name)
return(merged)
}
abort = import_topic(topic_name = "abort")
View(abort)
library(tidyverse)
import_topic = function(topic_name){
preds = read.csv(paste0("./final_outputs/", topic_name, "_preds.csv"))
true = read.csv(paste0("./final_outputs/", topic_name, "_true.csv"))
names(preds) = c("obs_num", "predicted_label")
names(true) = c("obs_num", "true_label")
merged = merge(preds, true, by = "obs_num") %>%
mutate(topic = topic_name)
return(merged)
}
aborti = import_topic(topic_name = "abort")
atheism = import_topic(topic_name = "atheism")
clim = import_topic(topic_name = "clim")
hil = import_topic(topic_name = "hil")
fem = import_topic(topic_name = "fem")
all_topics = bind_rows(abort, atheism, clim, hil, fem)
MLmetrics
install.packages("MLmetrics")
library(MLmetrics)
metrics = function(y_true, y_pred){
f1 = F1_Score(y_true = y_true, y_pred = y_pred)
return(f1)
}
metrics(y_true = abort$true_label, y_pred = abort$predicted_label)
metrics = function(y_true, y_pred){
f1 = F1_Score(y_true = y_true, y_pred = y_pred, positive = c(1,2))
return(f1)
}
metrics(y_true = abort$true_label, y_pred = abort$predicted_label)
metrics = function(y_true, y_pred){
f1 = F1_Score(y_true = y_true, y_pred = y_pred, positive = c("1","2"))
return(f1)
}
metrics(y_true = abort$true_label, y_pred = abort$predicted_label)
install.packages("ROCR")
import_topic = function(topic_name){
pred_labels = read.csv(paste0("./final_outputs/", topic_name, "_preds.csv"))
true_labels = read.csv(paste0("./final_outputs/", topic_name, "_true.csv"))
names(pred_labels) = c("obs_num", "predicted_label")
names(true_labels) = c("obs_num", "true_label")
merged = merge(pred_labels, true_labels, by = "obs_num") %>%
mutate(topic = topic_name
, pred_labels = factor(pred_labels)
, true_labels = factor(true_labels))
return(merged)
}
abort = import_topic(topic_name = "abort")
import_topic = function(topic_name){
pred_data = read.csv(paste0("./final_outputs/", topic_name, "_preds.csv"))
true_data = read.csv(paste0("./final_outputs/", topic_name, "_true.csv"))
names(pred_data) = c("obs_num", "predicted_label")
names(true_data) = c("obs_num", "true_label")
merged = merge(pred_data, true_data, by = "obs_num") %>%
mutate(topic = topic_name
, predicted_label = factor(predicted_label)
, true_label = factor(true_label))
return(merged)
}
abort = import_topic(topic_name = "abort")
atheism = import_topic(topic_name = "atheism")
clim = import_topic(topic_name = "clim")
hil = import_topic(topic_name = "hil")
fem = import_topic(topic_name = "fem")
all_topics = bind_rows(abort, atheism, clim, hil, fem)
View(abort)
ggplot(data =  abort %>% group_by(true_label, predicted_label) %>% summarise(n = n())
, mapping = aes(x = true_label, y = predicted_label)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
scale_fill_gradient(low = "white", high = "blue") +
theme_bw() + theme(legend.position = "none")
ggplot(data =  abort %>% group_by(true_label, predicted_label) %>% summarise(n = n())
, mapping = aes(x = true_label, y = predicted_label)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "blue") +
theme_bw() + theme(legend.position = "none")
library(tidyverse)
label_levels = c("Against", "Favor", "None")
import_topic = function(topic_name){
pred_data = read.csv(paste0("./final_outputs/", topic_name, "_preds.csv"))
true_data = read.csv(paste0("./final_outputs/", topic_name, "_true.csv"))
names(pred_data) = c("obs_num", "predicted_label")
names(true_data) = c("obs_num", "true_label")
merged = merge(pred_data, true_data, by = "obs_num") %>%
mutate(topic = topic_name
, predicted_label = case_when(predicted_label == 0 ~ "Against"
, predicted_label == 1 ~ "Favor"
, predicted_label == 1 ~ "None"
, TRUE ~ NA_real_) %>% factor(levels = label_levels)
, true_label = case_when(true_label == 0 ~ "Against"
, true_label == 1 ~ "Favor"
, true_label == 1 ~ "None"
, TRUE ~ NA_real_) %>% factor(levels = label_levels)
)
return(merged)
}
abort = import_topic(topic_name = "abort")
label_levels = c("Against", "Favor", "None")
import_topic = function(topic_name){
pred_data = read.csv(paste0("./final_outputs/", topic_name, "_preds.csv"))
true_data = read.csv(paste0("./final_outputs/", topic_name, "_true.csv"))
names(pred_data) = c("obs_num", "predicted_label")
names(true_data) = c("obs_num", "true_label")
merged = merge(pred_data, true_data, by = "obs_num") %>%
mutate(topic = topic_name
, predicted_label_f = case_when(predicted_label == 0 ~ "Against"
, predicted_label == 1 ~ "Favor"
, predicted_label == 1 ~ "None"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
, true_label_f = case_when(true_label == 0 ~ "Against"
, true_label == 1 ~ "Favor"
, true_label == 1 ~ "None"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
)
return(merged)
}
abort = import_topic(topic_name = "abort")
atheism = import_topic(topic_name = "atheism")
clim = import_topic(topic_name = "clim")
hil = import_topic(topic_name = "hil")
fem = import_topic(topic_name = "fem")
all_topics = bind_rows(abort, atheism, clim, hil, fem)
# metrics = function(y_true, y_pred){
#   f1 = F1_Score(y_true = y_true, y_pred = y_pred, positive = c("1","2"))
#
#   return(f1)
# }
#
# metrics(y_true = abort$true_label, y_pred = abort$predicted_label)
ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "blue") +
theme_bw() + theme(legend.position = "none")
label_levels = c("Against", "Favor", "None")
import_topic = function(topic_name){
pred_data = read.csv(paste0("./final_outputs/", topic_name, "_preds.csv"))
true_data = read.csv(paste0("./final_outputs/", topic_name, "_true.csv"))
names(pred_data) = c("obs_num", "predicted_label")
names(true_data) = c("obs_num", "true_label")
merged = merge(pred_data, true_data, by = "obs_num") %>%
mutate(topic = topic_name
, predicted_label_f = case_when(predicted_label == 0 ~ "Against"
, predicted_label == 1 ~ "Favor"
, predicted_label == 2 ~ "None"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
, true_label_f = case_when(true_label == 0 ~ "Against"
, true_label == 1 ~ "Favor"
, true_label == 2 ~ "None"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
)
return(merged)
}
abort = import_topic(topic_name = "abort")
atheism = import_topic(topic_name = "atheism")
clim = import_topic(topic_name = "clim")
hil = import_topic(topic_name = "hil")
fem = import_topic(topic_name = "fem")
all_topics = bind_rows(abort, atheism, clim, hil, fem)
# metrics = function(y_true, y_pred){
#   f1 = F1_Score(y_true = y_true, y_pred = y_pred, positive = c("1","2"))
#
#   return(f1)
# }
#
# metrics(y_true = abort$true_label, y_pred = abort$predicted_label)
ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "blue") +
theme_bw() + theme(legend.position = "none")
ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "blue") +
theme_bw() + theme(legend.position = "none") +
labs(x = "True Label", y = "Predicted Label")
ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "light blue") +
theme_bw() + theme(legend.position = "none") +
labs(x = "True Label", y = "Predicted Label")
ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "green") +
theme_bw() + theme(legend.position = "none") +
labs(x = "True Label", y = "Predicted Label")
library(tidyverse)
library(gridExtra)
library(htmltools)
label_levels = c("Against", "None", "Favor")
topic_name = "abort"
import_topic = function(topic_name){
tweet_data = read.csv(file = paste0("./final_outputs/", topic_name, "_tweets_v3.csv"), header = FALSE) %>%
# Check on why tweets have different index? probably maintain original whereas others are built from scratch
mutate(V1 = 1:n()-1)
pred_data = read.csv(file = paste0("./final_outputs/", topic_name, "_preds_v3.csv"), header = FALSE)
true_data = read.csv(file = paste0("./final_outputs/", topic_name, "_true_v3.csv"), header = FALSE)
names(pred_data) = c("obs_num", "predicted_label")
names(true_data) = c("obs_num", "true_label")
names(tweet_data) = c("obs_num", "tweet")
merged = tweet_data %>%
merge(pred_data
, by = "obs_num"
, all.x = TRUE) %>%
merge(true_data
, by = "obs_num"
, all.x = TRUE) %>%
mutate(topic = topic_name
, predicted_label_f = case_when(predicted_label == 0 ~ "Against"
, predicted_label == 1 ~ "None"
, predicted_label == 2 ~ "Favor"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
, true_label_f = case_when(true_label == 0 ~ "Against"
, true_label == 1 ~ "None"
, true_label == 2 ~ "Favor"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
)
return(merged)
}
abort = import_topic(topic_name = "abort")
atheism = import_topic(topic_name = "atheism")
clim = import_topic(topic_name = "clim")
hil = import_topic(topic_name = "hil")
fem = import_topic(topic_name = "fem")
all_topics = bind_rows(abort, atheism, clim, hil, fem)
metrics = function(y_true, y_pred){
confusion_matrix = as.matrix(table(Actual = y_true, Predicted = y_pred))
n = sum(confusion_matrix)
n_classes = nrow(confusion_matrix)
correct_byclass = diag(confusion_matrix)
instances_byclass = apply(confusion_matrix, 1, sum)
predictions_byclass = apply(confusion_matrix, 2, sum)
precision = correct_byclass / predictions_byclass
recall = correct_byclass / instances_byclass
f1 = 2 * precision * recall / (precision + recall)
classification_report = data.frame("Class" = label_levels
, "Precision" = round(precision * 100, 2)
, "Recall" = round(recall * 100, 2)
, "F1 Score" = round(f1 * 100, 2))
f1_macro = mean(f1)
f1_macro_custom = mean(f1[c(1,3)])
metric_list = list()
metric_list$confusion_matrix = confusion_matrix
metric_list$classification_report = classification_report
metric_list$f1_macro = f1_macro
metric_list$f1_macro_custom = f1_macro_custom
return(metric_list)
}
abort_metrics = metrics(y_true = abort$true_label_f, y_pred = abort$predicted_label_f)
atheism_metrics = metrics(y_true = atheism$true_label_f, y_pred = atheism$predicted_label_f)
clim_metrics = metrics(y_true = clim$true_label_f, y_pred = clim$predicted_label_f)
hil_metrics = metrics(y_true = hil$true_label_f, y_pred = hil$predicted_label_f)
fem_metrics = metrics(y_true = fem$true_label_f, y_pred = fem$predicted_label_f)
all_topics_metrics = metrics(y_true = all_topics$true_label_f, y_pred = all_topics$predicted_label_f)
# F stats
f_topics = c(atheism_metrics$f1_macro_custom
, clim_metrics$f1_macro_custom
, fem_metrics$f1_macro_custom
, hil_metrics$f1_macro_custom
, abort_metrics$f1_macro_custom)
f_summary = c(all_topics_metrics$f1_macro_custom
, mean(f_topics)
, f_topics)
f_summary = round(f_summary * 100, 2)
names(f_summary) = c("F-micro", "F-macro"
, "Atheism", "Climate Change", "Feminism", "Hillary Clinton", "Abortion")
# Confusion Plot
confusion_plot = ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "green4") +
theme_bw() + theme(legend.position = "none") +
labs(x = "True Label", y = "Predicted Label") +
scale_y_discrete(limits = rev(label_levels)) +
scale_x_discrete(limits = rev(label_levels)) +
labs(title = "All Topics")
grid.arrange(confusion_plot, tableGrob(all_topics_metrics$classification_report %>% select(-Class))
, tableGrob(data.frame("F1 Score" = f_summary))
, nrow = 2)
knitr::include_graphics(path = "images/bert_bytask.png")
measure_levels = c("F-micro", "F-macro", "Atheism", "Climate", "Feminism", "Hillary", "Abortion")
f_data = data.frame("measure" = c("F-micro", "F-macro", "Atheism", "Climate", "Feminism", "Hillary", "Abortion") %>%
factor(levels = measure_levels)
, "our_model" = f_summary
, "majority_classifer" = c(65.22,	40.092,	42.11,	42.12,	39.1,	36.83,	40.3)
) %>%
gather(key = "model", value = "value", -measure) %>%
mutate(custom_color = c(rep(1, 2), rep(3, 5)
, rep(2, 2), rep(4, 5)) %>% factor()) %>%
arrange(custom_color)
ggplot(data = f_data) +
geom_bar(aes(x = measure, y = value, fill = custom_color, group = model), colour = "black", stat = "identity", position = "dodge") +
scale_fill_manual(name = "Model", labels = c("Our Model - Aggregate", "Majority Classifier - Aggregate"
, "Our Model - by Topic", "Majority Classifier - by Topic"
)
, values = c("blue", "red", "cornflowerblue", "coral")) +
labs(x = "Topic/Measure", y = "Score")
# TO DO - color aggregate F scores differently
all_topics_errors = all_topics %>%
filter(predicted_label != true_label) %>%
select(obs_num, topic, tweet, predicted_label_f, true_label_f)
write.csv(all_topics_errors, file = "./final_outputs/all_topics_errors.csv")
### Abortion
## Potential negation?
# #pregnancyforall seems like a pro-choice tag but the "I have a right/power of choice" rhetoric is pro-choice
print(all_topics_errors %>% filter(obs_num == 6 & topic == "abort") %>% select(tweet) %>% as.character())
# There is no way to tall from the existing tweet
print(all_topics_errors %>% filter(obs_num == 10 & topic == "abort") %>% select(tweet) %>% as.character())
## Just wrong true label
# There is really no ambiguity here - this person is pro-abortion, should be FAVOR, labeled as AGAINST
print(all_topics_errors %>% filter(obs_num == 13 & topic == "abort") %>% select(tweet) %>% as.character())
library(tidyverse)
library(gridExtra)
library(htmltools)
label_levels = c("Against", "None", "Favor")
topic_name = "abort"
import_topic = function(topic_name){
tweet_data = read.csv(file = paste0("./final_outputs/", topic_name, "_tweets_v3.csv"), header = FALSE) %>%
# Check on why tweets have different index? probably maintain original whereas others are built from scratch
mutate(V1 = 1:n()-1)
pred_data = read.csv(file = paste0("./final_outputs/", topic_name, "_preds_v3.csv"), header = FALSE)
true_data = read.csv(file = paste0("./final_outputs/", topic_name, "_true_v3.csv"), header = FALSE)
names(pred_data) = c("obs_num", "predicted_label")
names(true_data) = c("obs_num", "true_label")
names(tweet_data) = c("obs_num", "tweet")
merged = tweet_data %>%
merge(pred_data
, by = "obs_num"
, all.x = TRUE) %>%
merge(true_data
, by = "obs_num"
, all.x = TRUE) %>%
mutate(topic = topic_name
, predicted_label_f = case_when(predicted_label == 0 ~ "Against"
, predicted_label == 1 ~ "None"
, predicted_label == 2 ~ "Favor"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
, true_label_f = case_when(true_label == 0 ~ "Against"
, true_label == 1 ~ "None"
, true_label == 2 ~ "Favor"
, TRUE ~ NA_character_) %>% factor(levels = label_levels)
)
return(merged)
}
abort = import_topic(topic_name = "abort")
atheism = import_topic(topic_name = "atheism")
clim = import_topic(topic_name = "clim")
hil = import_topic(topic_name = "hil")
fem = import_topic(topic_name = "fem")
all_topics = bind_rows(abort, atheism, clim, hil, fem)
metrics = function(y_true, y_pred){
confusion_matrix = as.matrix(table(Actual = y_true, Predicted = y_pred))
n = sum(confusion_matrix)
n_classes = nrow(confusion_matrix)
correct_byclass = diag(confusion_matrix)
instances_byclass = apply(confusion_matrix, 1, sum)
predictions_byclass = apply(confusion_matrix, 2, sum)
precision = correct_byclass / predictions_byclass
recall = correct_byclass / instances_byclass
f1 = 2 * precision * recall / (precision + recall)
classification_report = data.frame("Class" = label_levels
, "Precision" = round(precision * 100, 2)
, "Recall" = round(recall * 100, 2)
, "F1 Score" = round(f1 * 100, 2))
f1_macro = mean(f1)
f1_macro_custom = mean(f1[c(1,3)])
metric_list = list()
metric_list$confusion_matrix = confusion_matrix
metric_list$classification_report = classification_report
metric_list$f1_macro = f1_macro
metric_list$f1_macro_custom = f1_macro_custom
return(metric_list)
}
abort_metrics = metrics(y_true = abort$true_label_f, y_pred = abort$predicted_label_f)
atheism_metrics = metrics(y_true = atheism$true_label_f, y_pred = atheism$predicted_label_f)
clim_metrics = metrics(y_true = clim$true_label_f, y_pred = clim$predicted_label_f)
hil_metrics = metrics(y_true = hil$true_label_f, y_pred = hil$predicted_label_f)
fem_metrics = metrics(y_true = fem$true_label_f, y_pred = fem$predicted_label_f)
all_topics_metrics = metrics(y_true = all_topics$true_label_f, y_pred = all_topics$predicted_label_f)
# F stats
f_topics = c(atheism_metrics$f1_macro_custom
, clim_metrics$f1_macro_custom
, fem_metrics$f1_macro_custom
, hil_metrics$f1_macro_custom
, abort_metrics$f1_macro_custom)
f_summary = c(all_topics_metrics$f1_macro_custom
, mean(f_topics)
, f_topics)
f_summary = round(f_summary * 100, 2)
names(f_summary) = c("F-micro", "F-macro"
, "Atheism", "Climate Change", "Feminism", "Hillary Clinton", "Abortion")
# Confusion Plot
confusion_plot = ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
, mapping = aes(x = true_label_f, y = predicted_label_f)) +
geom_tile(aes(fill = n), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
scale_fill_gradient(low = "white", high = "green4") +
theme_bw() + theme(legend.position = "none") +
labs(x = "True Label", y = "Predicted Label") +
scale_y_discrete(limits = rev(label_levels)) +
scale_x_discrete(limits = rev(label_levels)) +
labs(title = "All Topics")
grid.arrange(confusion_plot, tableGrob(all_topics_metrics$classification_report %>% select(-Class))
, tableGrob(data.frame("F1 Score" = f_summary))
, nrow = 2)
knitr::include_graphics(path = "images/bert_bytask.png")
measure_levels = c("F-micro", "F-macro", "Atheism", "Climate", "Feminism", "Hillary", "Abortion")
f_data = data.frame("measure" = c("F-micro", "F-macro", "Atheism", "Climate", "Feminism", "Hillary", "Abortion") %>%
factor(levels = measure_levels)
, "our_model" = f_summary
, "majority_classifer" = c(65.22,	40.092,	42.11,	42.12,	39.1,	36.83,	40.3)
) %>%
gather(key = "model", value = "value", -measure) %>%
mutate(custom_color = c(rep(1, 2), rep(3, 5)
, rep(2, 2), rep(4, 5)) %>% factor()) %>%
arrange(custom_color)
ggplot(data = f_data) +
geom_bar(aes(x = measure, y = value, fill = custom_color, group = model), colour = "black", stat = "identity", position = "dodge") +
scale_fill_manual(name = "Model", labels = c("Our Model - Aggregate", "Majority Classifier - Aggregate"
, "Our Model - by Topic", "Majority Classifier - by Topic"
)
, values = c("blue", "red", "cornflowerblue", "coral")) +
labs(x = "Topic/Measure", y = "Score")
# TO DO - color aggregate F scores differently
all_topics_errors = all_topics %>%
filter(predicted_label != true_label) %>%
select(obs_num, topic, tweet, predicted_label_f, true_label_f)
write.csv(all_topics_errors, file = "./final_outputs/all_topics_errors.csv")
### Abortion
## Potential negation?
# #pregnancyforall seems like a pro-choice tag but the "I have a right/power of choice" rhetoric is pro-choice
print(all_topics_errors %>% filter(obs_num == 6 & topic == "abort") %>% select(tweet) %>% as.character())
# There is no way to tall from the existing tweet
print(all_topics_errors %>% filter(obs_num == 10 & topic == "abort") %>% select(tweet) %>% as.character())
## Just wrong true label
# There is really no ambiguity here - this person is pro-abortion, should be FAVOR, labeled as AGAINST
print(all_topics_errors %>% filter(obs_num == 13 & topic == "abort") %>% select(tweet) %>% as.character())
