{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PATH STUFF FIRST SO EASY TO SWITCH BETWEEN US ##\n",
    "\n",
    "# Set working directory\n",
    "# os.chdir(\"/Users/alexdessouky/Desktop/MIDS/w266\")\n",
    "os.chdir(\"/Users/manat/OneDrive/Documents/Tim/MIDS/266_NLP/Final Project\")\n",
    "\n",
    "# Store the paths to bert & data\n",
    "# bert_path =   '/Users/alexdessouky/Desktop/MIDS/w266/bert' \n",
    "# data_path = '/Users/alexdessouky/Desktop/MIDS/w266/w266_final_project/StanceDataset'  \n",
    "# bert_path =   '/Users/manat/OneDrive/Documents/Tim/MIDS/266_NLP/w266/bert' \n",
    "# data_path = '/Users/manat/OneDrive/Documents/Tim/MIDS/266_NLP/Final Project/w266_final_project/StanceDataset'  \n",
    "local_bert_path = r'C:\\Users\\manat\\OneDrive\\Documents\\Tim\\MIDS\\266_NLP\\w266\\bert\\\\' # change as needed\n",
    "data_path = r'C:\\Users\\manat\\OneDrive\\Documents\\Tim\\MIDS\\266_NLP\\Final Project\\w266_final_project\\StanceDataset'  \n",
    "\n",
    "# Make sure that the paths are accessible within the notebook\n",
    "sys.path.insert(0, bert_path)\n",
    "sys.path.insert(0, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System and Storage\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "now = datetime.now() # current date and time\n",
    "\n",
    "# Data structures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Strings\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Pre-Processing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from itertools import compress\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "import run_classifier_with_tfhub\n",
    "# Tensorflow hub path to BERT module of choice\n",
    "bert_url = \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\"\n",
    "\n",
    "# Outputs\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2914, 5)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "# Training data\n",
    "twitter_train = pd.read_excel('./w266_final_project/StanceDataset/train.xlsx')\n",
    "\n",
    "# Test data\n",
    "twitter_test = pd.read_excel('./w266_final_project/StanceDataset/test.xlsx')\n",
    "\n",
    "twitter_train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data  \n",
    "\n",
    "### Labels $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGAINST' 'FAVOR' 'NONE']\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# PREP LABELS FOR NN\n",
    "stance_train = np.array(twitter_train['Stance'])\n",
    "stance_test = np.array(twitter_test['Stance'])\n",
    "\n",
    "# One-hot Encoder\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(stance_train.reshape(-1, 1))\n",
    "label_categories = enc.categories_[0]\n",
    "\n",
    "labels_train = enc.transform(stance_train.reshape(-1, 1)).toarray()\n",
    "labels_test = enc.transform(stance_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(label_categories)\n",
    "print(labels_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: @tedcruz And, #HandOverTheServer she wiped clean + 30k deleted emails, explains dereliction of duty/lies re #Benghazi,etc #tcot\n",
      "Clean: @tedcruz and #handovertheserver she wiped clean  DIGITk deleted emails explains dereliction of dutylies re #benghazietc #tcot\n"
     ]
    }
   ],
   "source": [
    "def preprocess_tweets(x):\n",
    "    \n",
    "    # Remove punctuation EXCEPT for hashtags (#) and handles (@)\n",
    "    exclude_punc = [punc for punc in string.punctuation if punc not in ['#', '@']]\n",
    "    x_nopunc = ''.join(ch for ch in x if ch not in exclude_punc)\n",
    "\n",
    "    # lower case\n",
    "    x_lower = x_nopunc.lower()\n",
    "    \n",
    "    # Replace digits with DIGIT\n",
    "    x_digits = re.sub(\"\\d+\", \"DIGIT\", x_lower)\n",
    "    \n",
    "    return x_digits\n",
    "\n",
    "# Clean tweests\n",
    "twitter_train['tweet_clean'] = np.array(twitter_train['Tweet'].apply(lambda x: preprocess_tweets(x)))\n",
    "twitter_test['tweet_clean'] = np.array(twitter_test['Tweet'].apply(lambda x: preprocess_tweets(x)))\n",
    "\n",
    "# Example tweet\n",
    "print(\"Raw: \" + str(twitter_train['Tweet'][0]))\n",
    "print(\"Clean: \" + str(preprocess_tweets(twitter_train['Tweet'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @tedcruz and #handovertheserver she wiped clea...\n",
       "1    hillary is our best choice if we truly want to...\n",
       "2    @theview i think our country is ready for a fe...\n",
       "3    i just gave an unhealthy amount of my hardearn...\n",
       "4    @portiaaboulger thank you for adding me to you...\n",
       "Name: tweet_clean, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = twitter_train['tweet_clean']\n",
    "test_x = twitter_test['tweet_clean']\n",
    "\n",
    "train_x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_url = \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\"\n",
    "bert_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximal length of input 'sentences' (post tokenization).\n",
    "max_length = 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(bert_url)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens surrounded by the [CLS] and [SEP] tokens\n",
    "train_tokens = train_x.apply(lambda x: ['[CLS]'] + tokenizer.tokenize(x) + ['[SEP]'])\n",
    "test_tokens = test_x.apply(lambda x: ['[CLS]'] + tokenizer.tokenize(x) + ['[SEP]'])\n",
    "\n",
    "# Mask ids (mask out the paddings)\n",
    "train_mask_ids = train_tokens.apply(lambda x: len(x)*[1])\n",
    "test_mask_ids = test_tokens.apply(lambda x: len(x)*[1])\n",
    "\n",
    "train_mask_ids = train_mask_ids.apply(lambda x: np.array(x + (max_length - len(x)) * [0]) if len(x) < max_length else \n",
    "                                      np.array(x)).tolist()\n",
    "test_mask_ids = test_mask_ids.apply(lambda x: np.array(x + (max_length - len(x)) * [0]) if len(x) < max_length else \n",
    "                                    np.array(x)).tolist()\n",
    "\n",
    "# Add padding to tokens\n",
    "train_tokens = train_tokens.apply(lambda x: x + (max_length - len(x)) * ['[PAD]'] if len(x) < max_length else x)\n",
    "test_tokens = test_tokens.apply(lambda x: x + (max_length - len(x)) * ['[PAD]'] if len(x) < max_length else x)\n",
    "\n",
    "# Sequence vectors\n",
    "train_sequenceids = train_tokens.apply(lambda x: np.array(max_length*[0])).tolist()\n",
    "test_sequenceids = test_tokens.apply(lambda x: np.array(max_length*[0])).tolist()\n",
    "\n",
    "# Convert tokens to sentence ids\n",
    "train_sentenceids = train_tokens.apply(lambda x: np.array(tokenizer.convert_tokens_to_ids(x))).tolist()\n",
    "test_sentenceids = test_tokens.apply(lambda x: np.array(tokenizer.convert_tokens_to_ids(x))).tolist()\n",
    "\n",
    "# Bert features\n",
    "bert_train = [np.array(train_sentenceids), np.array(train_mask_ids), np.array(train_sequenceids)]\n",
    "bert_test = [np.array(test_sentenceids), np.array(test_mask_ids), np.array(test_sequenceids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tedcruz and #handovertheserver she wiped clean  DIGITk deleted emails explains dereliction of dutylies re #benghazietc #tcot\n",
      "['[CLS]', '@', 'te', '##d', '##c', '##ru', '##z', 'and', '#', 'hand', '##over', '##the', '##serve', '##r', 'she', 'wiped', 'clean', 'D', '##IG', '##IT', '##k', 'deleted', 'emails', 'explains', 'der', '##eli', '##ction', 'of', 'duty', '##lies', 're', '#', 'ben', '##gh', '##azi', '##et', '##c', '#', 't', '##cot', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(train_tokens[0])\n",
    "\n",
    "# NOTES: why such small tokens? e.g. benghazi has to be an important token by itself, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_mask_ids[0])\n",
    "\n",
    "# NOTES: unclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '@', 'te', '##d', '##c', '##ru', '##z', 'and', '#', 'hand', '##over', '##the', '##serve', '##r', 'she', 'wiped', 'clean', 'D', '##IG', '##IT', '##k', 'deleted', 'emails', 'explains', 'der', '##eli', '##ction', 'of', 'duty', '##lies', 're', '#', 'ben', '##gh', '##azi', '##et', '##c', '#', 't', '##cot', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens[0])\n",
    "\n",
    "# NOTES: every tweet same length of tokens (max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[ 101 4665 3113 1110 1412 1436 3026 1191 1195 5098 1328 1106 2760 1217\n",
      "  170 8706 3790  108 9294 2660  102    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_sequenceids[0])\n",
    "print(train_sequenceids[100])\n",
    "print(train_sentenceids[1])\n",
    "\n",
    "# NOTES: what are sequence ids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  101,   137, 21359, ...,     0,     0,     0],\n",
      "       [  101,  4665,  3113, ...,     0,     0,     0],\n",
      "       [  101,   137,  1103, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,  1293,  9164, ...,     0,     0,     0],\n",
      "       [  101,  4463,  2266, ...,     0,     0,     0],\n",
      "       [  101,   108,  9814, ...,     0,     0,     0]]), array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])]\n"
     ]
    }
   ],
   "source": [
    "print(bert_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset by Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2914\n",
      "2914\n",
      "2914\n",
      "(2914, 3)\n",
      "1956\n",
      "1956\n",
      "1956\n",
      "(1956, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentenceids))\n",
    "print(len(train_mask_ids))\n",
    "print(len(train_sequenceids))\n",
    "print(labels_train.shape)\n",
    "\n",
    "print(len(test_sentenceids))\n",
    "print(len(test_mask_ids))\n",
    "print(len(test_sequenceids))\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hillary\n",
    "topic_list = ['hillary clinton']\n",
    "matches_hillary_train = np.array(twitter_train['Target'].apply(lambda x: x.lower() in topic_list))\n",
    "matches_hillary_test = np.array(twitter_test['Target'].apply(lambda x: x.lower() in topic_list))\n",
    "\n",
    "labels_train_hillary = labels_train[matches_hillary_train,]\n",
    "labels_test_hillary = labels_test[matches_hillary_test,]\n",
    "\n",
    "train_sentenceids_hillary = list(compress(train_sentenceids, matches_hillary_train))\n",
    "train_mask_ids_hillary = list(compress(train_mask_ids, matches_hillary_train))\n",
    "train_sequenceids_hillary = list(compress(train_sequenceids, matches_hillary_train))\n",
    "test_sentenceids_hillary = list(compress(test_sentenceids, matches_hillary_test))\n",
    "test_mask_ids_hillary = list(compress(test_mask_ids, matches_hillary_test))\n",
    "test_sequenceids_hillary = list(compress(test_sequenceids, matches_hillary_test))\n",
    "\n",
    "bert_train_hillary = [np.array(train_sentenceids_hillary), \n",
    "                      np.array(train_mask_ids_hillary), \n",
    "                      np.array(train_sequenceids_hillary)]\n",
    "bert_test_hillary = [np.array(test_sentenceids_hillary), \n",
    "                     np.array(test_mask_ids_hillary), \n",
    "                     np.array(test_sequenceids_hillary)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n",
      "689\n",
      "689\n",
      "(689, 3)\n",
      "295\n",
      "295\n",
      "295\n",
      "(295, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentenceids_hillary))\n",
    "print(len(train_mask_ids_hillary))\n",
    "print(len(train_sequenceids_hillary))\n",
    "print(labels_train_hillary.shape)\n",
    "\n",
    "print(len(test_sentenceids_hillary))\n",
    "print(len(test_mask_ids_hillary))\n",
    "print(len(test_sequenceids_hillary))\n",
    "print(labels_test_hillary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer to create Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            bert_url,\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        trainable_vars = self.bert.variables\n",
    "        \n",
    "        # Remove unused layers\n",
    "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "        \n",
    "        # Select how many layers to fine tune\n",
    "        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "        \n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "        \n",
    "        # Add non-trainable weights\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        \n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "            \"pooled_output\"\n",
    "        ]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES: \n",
    "    # why have max_input_length as a parameter when we use max_length?\n",
    "\n",
    "def bert_model(max_input_length, train_layers, optimizer = tf.keras.optimizers.Adam(learning_rate=1)):\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_input_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_input_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_input_length,), name=\"segment_ids\")\n",
    "    \n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_sequence = BertLayer(n_fine_tune_layers = train_layers)(bert_inputs)\n",
    "    \n",
    "    #dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
    "    \n",
    "    dropout = tf.keras.layers.Dropout(rate=0.3)(bert_sequence)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(3, activation='softmax', name='classification')(dropout)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics = ['categorical_accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6962962962962963, 1: 1.289951305887561, 2: 1.268059181897302}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_class = compute_class_weight('balanced', np.unique(stance_train), stance_train)\n",
    "weights = {0: compute_class[0], 1:compute_class[1], 2:compute_class[2]}\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 83)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 83)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 83)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_7 (BertLayer)        (None, 768)          108931396   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 768)          0           bert_layer_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 3)            2307        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 108,933,703\n",
      "Trainable params: 6,498,051\n",
      "Non-trainable params: 102,435,652\n",
      "__________________________________________________________________________________________________\n",
      "Train on 551 samples, validate on 138 samples\n",
      "Epoch 1/30\n",
      "551/551 [==============================] - 276s 501ms/sample - loss: 1.2061 - categorical_accuracy: 0.4247 - val_loss: 0.7519 - val_categorical_accuracy: 0.5652\n",
      "Epoch 2/30\n",
      "551/551 [==============================] - 278s 505ms/sample - loss: 0.9353 - categorical_accuracy: 0.5426 - val_loss: 1.0403 - val_categorical_accuracy: 0.1884\n",
      "Epoch 3/30\n",
      "551/551 [==============================] - 281s 510ms/sample - loss: 0.8300 - categorical_accuracy: 0.5917 - val_loss: 1.0665 - val_categorical_accuracy: 0.6014\n",
      "Epoch 4/30\n",
      "551/551 [==============================] - 286s 520ms/sample - loss: 0.5223 - categorical_accuracy: 0.7586 - val_loss: 0.6226 - val_categorical_accuracy: 0.6739\n",
      "Epoch 5/30\n",
      "551/551 [==============================] - 288s 522ms/sample - loss: 0.3995 - categorical_accuracy: 0.8421 - val_loss: 1.3343 - val_categorical_accuracy: 0.5362\n",
      "Epoch 6/30\n",
      "551/551 [==============================] - 286s 520ms/sample - loss: 0.2647 - categorical_accuracy: 0.8748 - val_loss: 1.0581 - val_categorical_accuracy: 0.6087\n",
      "Epoch 7/30\n",
      "551/551 [==============================] - 288s 523ms/sample - loss: 0.1046 - categorical_accuracy: 0.9583 - val_loss: 1.4529 - val_categorical_accuracy: 0.5507\n",
      "Epoch 8/30\n",
      "551/551 [==============================] - 294s 534ms/sample - loss: 0.1160 - categorical_accuracy: 0.9601 - val_loss: 1.3066 - val_categorical_accuracy: 0.6449\n",
      "Epoch 9/30\n",
      "551/551 [==============================] - 288s 523ms/sample - loss: 0.0782 - categorical_accuracy: 0.9800 - val_loss: 1.6376 - val_categorical_accuracy: 0.6522\n",
      "Epoch 10/30\n",
      "551/551 [==============================] - 295s 535ms/sample - loss: 0.0364 - categorical_accuracy: 0.9837 - val_loss: 2.3438 - val_categorical_accuracy: 0.4783\n",
      "Epoch 11/30\n",
      "551/551 [==============================] - 293s 532ms/sample - loss: 0.0697 - categorical_accuracy: 0.9764 - val_loss: 1.4105 - val_categorical_accuracy: 0.6377\n",
      "Epoch 12/30\n",
      "551/551 [==============================] - 292s 530ms/sample - loss: 0.0425 - categorical_accuracy: 0.9837 - val_loss: 1.8648 - val_categorical_accuracy: 0.5290\n",
      "Epoch 13/30\n",
      "551/551 [==============================] - 297s 539ms/sample - loss: 0.0473 - categorical_accuracy: 0.9800 - val_loss: 1.6656 - val_categorical_accuracy: 0.5797\n",
      "Epoch 14/30\n",
      "551/551 [==============================] - 295s 536ms/sample - loss: 0.0694 - categorical_accuracy: 0.9800 - val_loss: 1.5062 - val_categorical_accuracy: 0.5507\n",
      "Epoch 15/30\n",
      "551/551 [==============================] - 297s 540ms/sample - loss: 0.0530 - categorical_accuracy: 0.9873 - val_loss: 1.8332 - val_categorical_accuracy: 0.6014\n",
      "Epoch 16/30\n",
      "551/551 [==============================] - 294s 534ms/sample - loss: 0.0201 - categorical_accuracy: 0.9946 - val_loss: 1.8191 - val_categorical_accuracy: 0.6304\n",
      "Epoch 17/30\n",
      "551/551 [==============================] - 303s 549ms/sample - loss: 0.0158 - categorical_accuracy: 0.9946 - val_loss: 1.3284 - val_categorical_accuracy: 0.6957\n",
      "Epoch 18/30\n",
      "551/551 [==============================] - 297s 539ms/sample - loss: 0.0030 - categorical_accuracy: 1.0000 - val_loss: 1.9621 - val_categorical_accuracy: 0.6377\n",
      "Epoch 19/30\n",
      "551/551 [==============================] - 296s 536ms/sample - loss: 0.0024 - categorical_accuracy: 1.0000 - val_loss: 2.4911 - val_categorical_accuracy: 0.5870\n",
      "Epoch 20/30\n",
      "551/551 [==============================] - 294s 533ms/sample - loss: 0.0050 - categorical_accuracy: 0.9982 - val_loss: 2.3454 - val_categorical_accuracy: 0.6377\n",
      "Epoch 21/30\n",
      "551/551 [==============================] - 294s 533ms/sample - loss: 0.0048 - categorical_accuracy: 0.9982 - val_loss: 2.1007 - val_categorical_accuracy: 0.6957\n",
      "Epoch 22/30\n",
      "551/551 [==============================] - 295s 535ms/sample - loss: 0.0081 - categorical_accuracy: 0.9964 - val_loss: 2.1835 - val_categorical_accuracy: 0.6594\n",
      "Epoch 23/30\n",
      "551/551 [==============================] - 289s 525ms/sample - loss: 0.0026 - categorical_accuracy: 0.9982 - val_loss: 2.4116 - val_categorical_accuracy: 0.6449\n",
      "Epoch 24/30\n",
      "551/551 [==============================] - 290s 526ms/sample - loss: 5.3352e-04 - categorical_accuracy: 1.0000 - val_loss: 2.7972 - val_categorical_accuracy: 0.6159\n",
      "Epoch 25/30\n",
      "551/551 [==============================] - 291s 528ms/sample - loss: 4.5811e-05 - categorical_accuracy: 1.0000 - val_loss: 2.6806 - val_categorical_accuracy: 0.6304\n",
      "Epoch 26/30\n",
      "551/551 [==============================] - 290s 526ms/sample - loss: 2.6374e-05 - categorical_accuracy: 1.0000 - val_loss: 2.6505 - val_categorical_accuracy: 0.6377\n",
      "Epoch 27/30\n",
      "551/551 [==============================] - 291s 528ms/sample - loss: 1.8175e-05 - categorical_accuracy: 1.0000 - val_loss: 2.6389 - val_categorical_accuracy: 0.6377\n",
      "Epoch 28/30\n",
      "551/551 [==============================] - 290s 526ms/sample - loss: 2.3844e-05 - categorical_accuracy: 1.0000 - val_loss: 2.6315 - val_categorical_accuracy: 0.6377\n",
      "Epoch 29/30\n",
      "551/551 [==============================] - 289s 524ms/sample - loss: 3.0470e-05 - categorical_accuracy: 1.0000 - val_loss: 2.6284 - val_categorical_accuracy: 0.6377\n",
      "Epoch 30/30\n",
      "551/551 [==============================] - 289s 525ms/sample - loss: 1.7776e-05 - categorical_accuracy: 1.0000 - val_loss: 2.6247 - val_categorical_accuracy: 0.6304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1718183b978>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Start session\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "model = bert_model(max_input_length = max_length, # + 1 \n",
    "                   train_layers = 12, \n",
    "                   optimizer = 'adam')\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model.fit(\n",
    "    x = bert_train_hillary, \n",
    "    y = labels_train_hillary,\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    epochs = 30,\n",
    "    verbose = 1,\n",
    "    batch_size=32,\n",
    "    class_weight = weights\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hillary = model.predict(bert_test_hillary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0, 2, 1, 0, 2, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 2, 2, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2,\n",
       "       2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0,\n",
       "       0, 0, 2, 1, 2, 0, 2, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 2, 0,\n",
       "       0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0,\n",
       "       0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 1, 2, 0, 2, 2, 0, 2, 0, 0, 2,\n",
       "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 2, 0, 0, 0,\n",
       "       2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 1, 0, 2, 2, 0, 2, 0, 0,\n",
       "       0, 2, 2, 0, 1, 2, 0, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test_hillary, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_plot(confusion_matrix, target_names):\n",
    "    # Plot confusion matrix (via imshow)\n",
    "    plt.imshow(confusion_matrix, interpolation = \"nearest\", cmap = plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Loop through each value of the matrix to add data labels\n",
    "    width, height = confusion_matrix.shape\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate(str(confusion_matrix[x][y]), xy = (y, x), \n",
    "                        horizontalalignment = \"center\",\n",
    "                        verticalalignment = \"center\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    \n",
    "def metrics(true_labels_in, test_probs):\n",
    "    \n",
    "    #find predicted labels\n",
    "    test_predicts = np.argmax(test_probs, axis = 1)\n",
    "    true_labels = np.argmax(true_labels_in, axis = 1)\n",
    "    \n",
    "    #calculate f1 score\n",
    "    f1 = f1_score(true_labels, test_predicts, average = 'macro')\n",
    "    \n",
    "    print(\"F1 macro score:\", f1)\n",
    "    \n",
    "    print(classification_report(y_true = true_labels, \n",
    "                                        y_pred = test_predicts,\n",
    "                                        target_names = ['Against', 'None', 'Favor']))\n",
    "    \n",
    "    confuse = confusion_matrix(y_true = true_labels, y_pred = test_predicts)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    confusion_plot(confuse, ['Against', 'None', 'Favor'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 macro score: 0.6099603824497372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Against       0.74      0.74      0.74       172\n",
      "        None       0.54      0.31      0.39        45\n",
      "       Favor       0.63      0.78      0.70        78\n",
      "\n",
      "    accuracy                           0.68       295\n",
      "   macro avg       0.64      0.61      0.61       295\n",
      "weighted avg       0.68      0.68      0.67       295\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics(true_labels_in = labels_test_hillary, \n",
    "        test_probs = test_hillary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
