{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Stance Detection  \n",
    "W266 - NLP  \n",
    "Alex Dessouky & Tim Spittle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup  \n",
    "\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System and Storage\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "now = datetime.now() # current date and time\n",
    "\n",
    "# Data structures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Strings\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Pre-Processing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from itertools import compress\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "\n",
    "# Outputs\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths & Local Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PATH STUFF FIRST SO EASY TO SWITCH BETWEEN US ##\n",
    "\n",
    "# Set working directory\n",
    "# os.chdir(\"/Users/alexdessouky/Desktop/MIDS/w266\")\n",
    "# os.chdir(\"/Users/manat/OneDrive/Documents/Tim/MIDS/266_NLP/Final Project\")\n",
    "\n",
    "# Store the paths to bert & data\n",
    "# bert_path =   '/Users/alexdessouky/Desktop/MIDS/w266/bert' \n",
    "# data_path = '/Users/alexdessouky/Desktop/MIDS/w266/w266_final_project/StanceDataset'  \n",
    "# TIM LOCAL\n",
    "# bert_path = r'C:\\Users\\manat\\OneDrive\\Documents\\Tim\\MIDS\\266_NLP\\w266\\bert\\\\' # change as needed\n",
    "# data_path = r'C:\\Users\\manat\\OneDrive\\Documents\\Tim\\MIDS\\266_NLP\\Final Project\\w266_final_project\\StanceDataset'  \n",
    "# TIM CLOUD\n",
    "bert_path = r'/home/timspittle/w266_final_project/bert/' \n",
    "data_path = r'/home/timspittle/w266_final_project/StanceDataset/'  \n",
    "\n",
    "# Make sure that the paths are accessible within the notebook\n",
    "sys.path.insert(0, bert_path)\n",
    "sys.path.insert(0, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/timspittle/w266_final_project/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Packages imported from bert local path\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "import run_classifier_with_tfhub\n",
    "\n",
    "# Tensorflow hub path to BERT module of choice\n",
    "bert_url = \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (shape): (2914, 5)\n",
      "Test (shape): (1956, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Target</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Opinion Towards</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion abo...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hillary is our best choice if we truly want to...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion abo...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@TheView I think our country is ready for a fe...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion abo...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion abo...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3.  The tweet is not explicitly expressing opi...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet           Target  \\\n",
       "0  @tedcruz And, #HandOverTheServer she wiped cle...  Hillary Clinton   \n",
       "1  Hillary is our best choice if we truly want to...  Hillary Clinton   \n",
       "2  @TheView I think our country is ready for a fe...  Hillary Clinton   \n",
       "3  I just gave an unhealthy amount of my hard-ear...  Hillary Clinton   \n",
       "4  @PortiaABoulger Thank you for adding me to you...  Hillary Clinton   \n",
       "\n",
       "    Stance                                    Opinion Towards Sentiment  \n",
       "0  AGAINST  1.  The tweet explicitly expresses opinion abo...       neg  \n",
       "1    FAVOR  1.  The tweet explicitly expresses opinion abo...       pos  \n",
       "2  AGAINST  1.  The tweet explicitly expresses opinion abo...       neg  \n",
       "3  AGAINST  1.  The tweet explicitly expresses opinion abo...       neg  \n",
       "4     NONE  3.  The tweet is not explicitly expressing opi...       pos  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "# Training data\n",
    "# twitter_train = pd.read_excel('./w266_final_project/StanceDataset/train.xlsx')\n",
    "twitter_train_raw = pd.read_excel('./StanceDataset/train.xlsx')\n",
    "\n",
    "# Test data\n",
    "# twitter_test = pd.read_excel('./w266_final_project/StanceDataset/test.xlsx')\n",
    "twitter_test_raw = pd.read_excel('./StanceDataset/test.xlsx')\n",
    "\n",
    "print(\"Training (shape): \" + str(twitter_train_raw.shape))\n",
    "print(\"Test (shape): \" + str(twitter_test_raw.shape))\n",
    "twitter_train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data  \n",
    "\n",
    "### Labels $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGAINST' 'FAVOR' 'NONE']\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Text Labels (needed for plotting)\n",
    "labels_text_train = np.array(twitter_train_raw['Stance'])\n",
    "labels_text_test = np.array(twitter_test_raw['Stance'])\n",
    "\n",
    "# One-hot Encoder\n",
    "enc_labels = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc_labels.fit(labels_text_train.reshape(-1, 1))\n",
    "label_categories = enc_labels.categories_[0]\n",
    "\n",
    "# Encoded Labels (for NN)\n",
    "labels_encoded_train = enc_labels.transform(labels_text_train.reshape(-1, 1)).toarray()\n",
    "labels_encoded_test = enc_labels.transform(labels_text_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(label_categories)\n",
    "print(labels_encoded_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: @tedcruz And, #HandOverTheServer she wiped clean + 30k deleted emails, explains dereliction of duty/lies re #Benghazi,etc #tcot\n",
      "Clean: @tedcruz and #handovertheserver she wiped clean  DIGITk deleted emails explains dereliction of dutylies re #benghazietc #tcot\n"
     ]
    }
   ],
   "source": [
    "def preprocess_tweets(x):\n",
    "    \n",
    "    # Remove punctuation EXCEPT for hashtags (#) and handles (@)\n",
    "    exclude_punc = [punc for punc in string.punctuation if punc not in ['#', '@']]\n",
    "    x_nopunc = ''.join(ch for ch in x if ch not in exclude_punc)\n",
    "\n",
    "    # lower case\n",
    "    x_lower = x_nopunc.lower()\n",
    "    \n",
    "    # Replace digits with DIGIT\n",
    "    x_digits = re.sub(\"\\d+\", \"DIGIT\", x_lower)\n",
    "    \n",
    "    return x_digits\n",
    "\n",
    "# Clean tweests\n",
    "twitter_train_raw['tweet_prep'] = np.array(twitter_train_raw['Tweet'].apply(lambda x: preprocess_tweets(x)))\n",
    "twitter_test_raw['tweet_prep'] = np.array(twitter_test_raw['Tweet'].apply(lambda x: preprocess_tweets(x)))\n",
    "\n",
    "# Example tweet\n",
    "print(\"Raw: \" + str(twitter_train_raw['Tweet'][0]))\n",
    "print(\"Clean: \" + str(preprocess_tweets(twitter_train_raw['Tweet'][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/timspittle/w266_final_project/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/timspittle/w266_final_project/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(bert_url)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens surrounded by the [CLS] and [SEP] tokens\n",
    "tokens_train = twitter_train_raw['tweet_prep'].apply(lambda x: ['[CLS]'] + tokenizer.tokenize(x) + ['[SEP]'])\n",
    "tokens_test = twitter_test_raw['tweet_prep'].apply(lambda x: ['[CLS]'] + tokenizer.tokenize(x) + ['[SEP]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximal length of input 'sentences' (post tokenization).\n",
    "sen_length_list = []\n",
    "for sent in tokens_train.append(tokens_test):\n",
    "    sen_length_list.append(len(sent))\n",
    "max_length = np.max(sen_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_lists(tokens_in, max_length_in):\n",
    "\n",
    "    # Mask ids (mask out the paddings)\n",
    "    mask_ids = tokens_in.apply(lambda x: len(x)*[1])\n",
    "    \n",
    "    mask_ids = mask_ids.apply(lambda x: np.array(x + (max_length_in - len(x)) * [0])\n",
    "                              if len(x) < max_length_in else np.array(x)).tolist()\n",
    "    \n",
    "    # Add padding to tokens\n",
    "    tokens_pad = tokens_in.apply(lambda x: x + (max_length_in - len(x)) * ['[PAD]'] if len(x) < max_length_in else x)\n",
    "    \n",
    "    # Sequence vectors\n",
    "    sequenceids = tokens_pad.apply(lambda x: np.array(max_length_in*[0])).tolist()\n",
    "    \n",
    "    # Convert tokens to sentence ids\n",
    "    sentenceids = tokens_pad.apply(lambda x: tokenizer.convert_tokens_to_ids(x)).tolist()\n",
    "    \n",
    "    # Bert features\n",
    "    bert = [np.array(sentenceids), np.array(mask_ids), np.array(sequenceids)]\n",
    "    return(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train = bert_lists(tokens_in = tokens_train, max_length_in = max_length)\n",
    "bert_test = bert_lists(tokens_in = tokens_test, max_length_in = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tedcruz and #handovertheserver she wiped clean  DIGITk deleted emails explains dereliction of dutylies re #benghazietc #tcot\n",
      "['[CLS]', '@', 'te', '##d', '##c', '##ru', '##z', 'and', '#', 'hand', '##over', '##the', '##serve', '##r', 'she', 'wiped', 'clean', 'D', '##IG', '##IT', '##k', 'deleted', 'emails', 'explains', 'der', '##eli', '##ction', 'of', 'duty', '##lies', 're', '#', 'ben', '##gh', '##azi', '##et', '##c', '#', 't', '##cot', '[SEP]']\n",
      "[[  101   137 21359 ...     0     0     0]\n",
      " [  101  4665  3113 ...     0     0     0]\n",
      " [  101   137  1103 ...     0     0     0]\n",
      " ...\n",
      " [  101  1293  9164 ...     0     0     0]\n",
      " [  101  4463  2266 ...     0     0     0]\n",
      " [  101   108  9814 ...     0     0     0]]\n",
      "[[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(twitter_train_raw['tweet_prep'][0])\n",
    "print(tokens_train[0])\n",
    "# NOTES: why such small tokens? e.g. benghazi and ted cruz have to be important tokens by themselves, right?\n",
    "    # If mask token is \"#\" we're losing out on hashtags\n",
    "print(bert_train[0])\n",
    "# NOTES: converting tokens to IDs makes sense, why call them sentence IDs?\n",
    "print(bert_train[1])\n",
    "# NOTES: is this just a 0 for PADs?\n",
    "print(bert_train[2])\n",
    "# NOTES: what the hell is this? all 0's?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2914, 95), (2914, 95), (2914, 95)\n",
      "(2914, 3)\n",
      "(1956, 95), (1956, 95), (1956, 95)\n",
      "(1956, 3)\n"
     ]
    }
   ],
   "source": [
    "# CHECK SIZES\n",
    "print(str(bert_train[0].shape) +\", \"+  str(bert_train[1].shape) +\", \"+ str(bert_train[2].shape))\n",
    "print(labels_encoded_train.shape)\n",
    "\n",
    "print(str(bert_test[0].shape) +\", \"+  str(bert_test[1].shape) +\", \"+ str(bert_test[2].shape))\n",
    "print(labels_encoded_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset by Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_subset(targets_in, labels_text_in, labels_encoded_in, bert_in, topic_in):\n",
    "        \n",
    "    # Convert topic lower case\n",
    "    topic_in = topic_in.lower()\n",
    "    \n",
    "    # Find boolean series of all rows pertaining to the relevant topics\n",
    "    matches_target_topic = targets_in.apply(lambda x: x.lower() == topic_in)\n",
    "    \n",
    "    # LABELS\n",
    "    labels_text_sub = labels_text_in[matches_target_topic]\n",
    "    labels_encoded_sub = labels_encoded_in[matches_target_topic,:]\n",
    "    compute_class = compute_class_weight('balanced', np.unique(labels_text_sub), labels_text_sub)\n",
    "    weights = {0: compute_class[0], 1:compute_class[1], 2:compute_class[2]}\n",
    "    \n",
    "    # BERT\n",
    "    bert_sub = []\n",
    "    for input_list in bert_in:\n",
    "        bert_sub.append(input_list[matches_target_topic])\n",
    "        \n",
    "    # Output Dictionary\n",
    "    subset_dict = {}\n",
    "    subset_dict['target'] = topic_in\n",
    "    subset_dict['labels_text'] = labels_text_sub\n",
    "    subset_dict['labels_encoded'] = labels_encoded_sub\n",
    "    subset_dict['class_weights'] = weights\n",
    "    subset_dict['bert'] = bert_sub\n",
    "    \n",
    "    return subset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Legalization of Abortion',\n",
       " 'Climate Change is a Real Concern',\n",
       " 'Hillary Clinton',\n",
       " 'Atheism',\n",
       " 'Feminist Movement']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(set(twitter_train_raw['Target']))\n",
    "target_abortion = target_list[0]\n",
    "target_atheism = target_list[1]\n",
    "target_climate_change = target_list[2]\n",
    "target_feminism = target_list[3]\n",
    "target_hillary = target_list[4]\n",
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Abortion\n",
    "abortion_train_subset = topic_subset(targets_in = twitter_train_raw['Target'], \n",
    "                                    labels_text_in = labels_text_train, \n",
    "                                    labels_encoded_in = labels_encoded_train, \n",
    "                                    bert_in = bert_train, \n",
    "                                    topic_in = target_abortion)\n",
    "\n",
    "abortion_test_subset = topic_subset(targets_in = twitter_test_raw['Target'], \n",
    "                                    labels_text_in = labels_text_test, \n",
    "                                    labels_encoded_in = labels_encoded_test, \n",
    "                                    bert_in = bert_test, \n",
    "                                    topic_in = target_abortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Atheism\n",
    "atheism_train_subset = topic_subset(targets_in = twitter_train_raw['Target'], \n",
    "                                    labels_text_in = labels_text_train, \n",
    "                                    labels_encoded_in = labels_encoded_train, \n",
    "                                    bert_in = bert_train, \n",
    "                                    topic_in = target_atheism)\n",
    "\n",
    "atheism_test_subset = topic_subset(targets_in = twitter_test_raw['Target'], \n",
    "                                    labels_text_in = labels_text_test, \n",
    "                                    labels_encoded_in = labels_encoded_test, \n",
    "                                    bert_in = bert_test, \n",
    "                                    topic_in = target_atheism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Climate Change\n",
    "climate_change_train_subset = topic_subset(targets_in = twitter_train_raw['Target'], \n",
    "                                    labels_text_in = labels_text_train, \n",
    "                                    labels_encoded_in = labels_encoded_train, \n",
    "                                    bert_in = bert_train, \n",
    "                                    topic_in = target_climate_change)\n",
    "\n",
    "climate_change_test_subset = topic_subset(targets_in = twitter_test_raw['Target'], \n",
    "                                    labels_text_in = labels_text_test, \n",
    "                                    labels_encoded_in = labels_encoded_test, \n",
    "                                    bert_in = bert_test, \n",
    "                                    topic_in = target_climate_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Feminism\n",
    "feminism_train_subset = topic_subset(targets_in = twitter_train_raw['Target'], \n",
    "                                    labels_text_in = labels_text_train, \n",
    "                                    labels_encoded_in = labels_encoded_train, \n",
    "                                    bert_in = bert_train, \n",
    "                                    topic_in = target_feminism)\n",
    "\n",
    "feminism_test_subset = topic_subset(targets_in = twitter_test_raw['Target'], \n",
    "                                    labels_text_in = labels_text_test, \n",
    "                                    labels_encoded_in = labels_encoded_test, \n",
    "                                    bert_in = bert_test, \n",
    "                                    topic_in = target_feminism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hillary\n",
    "hillary_train_subset = topic_subset(targets_in = twitter_train_raw['Target'], \n",
    "                                    labels_text_in = labels_text_train, \n",
    "                                    labels_encoded_in = labels_encoded_train, \n",
    "                                    bert_in = bert_train, \n",
    "                                    topic_in = target_hillary)\n",
    "\n",
    "hillary_test_subset = topic_subset(targets_in = twitter_test_raw['Target'], \n",
    "                                    labels_text_in = labels_text_test, \n",
    "                                    labels_encoded_in = labels_encoded_test, \n",
    "                                    bert_in = bert_test, \n",
    "                                    topic_in = target_hillary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_train_raw['Target']) == len(abortion_train_subset['labels_text']) + len(atheism_train_subset['labels_text']) + len(climate_change_train_subset['labels_text']) + len(feminism_train_subset['labels_text']) + len(hillary_train_subset['labels_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer to create Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            bert_url,\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        trainable_vars = self.bert.variables\n",
    "        \n",
    "        # Remove unused layers\n",
    "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name and not \"/pooler/\" in var.name]\n",
    "        \n",
    "        # Select how many layers to fine tune\n",
    "        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "        \n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "        \n",
    "        # Add non-trainable weights\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        \n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "            \"sequence_output\"\n",
    "        ]\n",
    "        \n",
    "        mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NTOE: paramterized a lot of this setup\n",
    "\n",
    "def bert_lstm_model(max_length_in, bert_fine_tune_layers, optimizer, learning_rate_in, dropout_rate_in):\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_length_in,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length_in,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length_in,), name=\"segment_ids\")\n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    bert_sequence = BertLayer(n_fine_tune_layers=bert_fine_tune_layers)(bert_inputs)\n",
    "    dropout1= tf.keras.layers.Dropout(rate=dropout_rate_in)(bert_sequence)\n",
    "    \n",
    "    # Bi-Directional?\n",
    "    lstm1 = tf.keras.layers.LSTM(128, name='lstm1')(dropout1)\n",
    "    \n",
    "    dense1 = tf.keras.layers.Dense(64, \n",
    "                                   activation='relu', \n",
    "                                   kernel_initializer = tf.keras.initializers.he_normal(), \n",
    "                                   name='dense1')(lstm1)\n",
    "    dropout2 = tf.keras.layers.Dropout(rate=dropout_rate_in)(dense1)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(3, activation='softmax', name='classification')(dropout2)\n",
    "    \n",
    "    tf.keras.optimizers.Adam(learning_rate=learning_rate_in)\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics = ['categorical_accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_plot(confusion_matrix, target_names):\n",
    "    # Plot confusion matrix (via imshow)\n",
    "    plt.imshow(confusion_matrix, interpolation = \"nearest\", cmap = plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.ylim([-0.5, 2.5]) # Fixed values for now\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Loop through each value of the matrix to add data labels\n",
    "    width, height = confusion_matrix.shape\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate(str(confusion_matrix[x][y]), xy = (y, x), \n",
    "                        horizontalalignment = \"center\",\n",
    "                        verticalalignment = \"center\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    \n",
    "def standard_metrics(true_labels, test_probs, label_titles):\n",
    "    # Find predicted labels\n",
    "    test_prob_max = np.argmax(test_probs, axis = 1)\n",
    "\n",
    "    test_predicts = []\n",
    "    for i in range(len(test_prob_max)):\n",
    "        test_predicts.append(label_titles[test_prob_max[i]])\n",
    "    \n",
    "    # F1 score\n",
    "    f1 = f1_score(true_labels, test_predicts, average = 'macro')\n",
    "    print(\"F1 macro score:\", f1)\n",
    "    \n",
    "    # Classification Report\n",
    "    print(classification_report(y_true = true_labels, \n",
    "                                        y_pred = test_predicts,\n",
    "                                        target_names = label_titles))\n",
    "    \n",
    "    # Confusion Matrix plot\n",
    "    confuse = confusion_matrix(y_true = true_labels, y_pred = test_predicts)\n",
    "    plt.figure(figsize = (20, 5))\n",
    "    confusion_plot(confuse, label_titles)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 95)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 95)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 95)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_10 (BertLayer)       (None, None, 768)    108931396   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, None, 768)    0           bert_layer_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 128)          459264      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 64)           8256        lstm1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 64)           0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 3)            195         dropout_21[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,399,111\n",
      "Trainable params: 6,963,459\n",
      "Non-trainable params: 102,435,652\n",
      "__________________________________________________________________________________________________\n",
      "Train on 522 samples, validate on 131 samples\n",
      "Epoch 1/15\n",
      "522/522 - 52s - loss: 1.2027 - categorical_accuracy: 0.3487 - val_loss: 0.9418 - val_categorical_accuracy: 0.1985\n",
      "Epoch 2/15\n",
      "522/522 - 42s - loss: 1.1526 - categorical_accuracy: 0.3276 - val_loss: 0.9125 - val_categorical_accuracy: 0.5878\n",
      "Epoch 3/15\n",
      "522/522 - 42s - loss: 1.0928 - categorical_accuracy: 0.4100 - val_loss: 0.8647 - val_categorical_accuracy: 0.3740\n",
      "Epoch 4/15\n",
      "522/522 - 42s - loss: 0.9742 - categorical_accuracy: 0.4962 - val_loss: 0.7806 - val_categorical_accuracy: 0.6565\n",
      "Epoch 5/15\n",
      "522/522 - 42s - loss: 0.8470 - categorical_accuracy: 0.5709 - val_loss: 0.9104 - val_categorical_accuracy: 0.4580\n",
      "Epoch 6/15\n",
      "522/522 - 42s - loss: 0.6725 - categorical_accuracy: 0.6801 - val_loss: 1.0509 - val_categorical_accuracy: 0.5191\n",
      "Epoch 7/15\n",
      "522/522 - 43s - loss: 0.5065 - categorical_accuracy: 0.7586 - val_loss: 1.4523 - val_categorical_accuracy: 0.4733\n",
      "Epoch 8/15\n",
      "522/522 - 43s - loss: 0.3884 - categorical_accuracy: 0.8084 - val_loss: 1.4260 - val_categorical_accuracy: 0.4962\n",
      "Epoch 9/15\n",
      "522/522 - 44s - loss: 0.3076 - categorical_accuracy: 0.8889 - val_loss: 1.9961 - val_categorical_accuracy: 0.5191\n",
      "Epoch 10/15\n",
      "522/522 - 45s - loss: 0.2526 - categorical_accuracy: 0.9100 - val_loss: 1.9477 - val_categorical_accuracy: 0.5573\n",
      "Epoch 11/15\n",
      "522/522 - 44s - loss: 0.2859 - categorical_accuracy: 0.8927 - val_loss: 2.6220 - val_categorical_accuracy: 0.5267\n",
      "Epoch 12/15\n",
      "522/522 - 43s - loss: 0.2841 - categorical_accuracy: 0.8966 - val_loss: 2.1353 - val_categorical_accuracy: 0.5115\n",
      "Epoch 13/15\n",
      "522/522 - 43s - loss: 0.2332 - categorical_accuracy: 0.9100 - val_loss: 2.9361 - val_categorical_accuracy: 0.4427\n",
      "Epoch 14/15\n",
      "522/522 - 43s - loss: 0.3074 - categorical_accuracy: 0.9119 - val_loss: 2.5560 - val_categorical_accuracy: 0.4198\n",
      "Epoch 15/15\n",
      "522/522 - 43s - loss: 0.3039 - categorical_accuracy: 0.8946 - val_loss: 2.0634 - val_categorical_accuracy: 0.4046\n",
      "F1 macro score: 0.46851603396979624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     AGAINST       0.88      0.35      0.51       189\n",
      "       FAVOR       0.30      0.78      0.43        46\n",
      "        NONE       0.36      0.67      0.47        45\n",
      "\n",
      "    accuracy                           0.48       280\n",
      "   macro avg       0.51      0.60      0.47       280\n",
      "weighted avg       0.70      0.47      0.49       280\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "model_abortion = bert_lstm_model(max_length_in = max_length, \n",
    "                                 bert_fine_tune_layers = 12, \n",
    "                                 optimizer = 'adam',\n",
    "                                 learning_rate_in = 0.1,\n",
    "                                 dropout_rate_in = 0.8)\n",
    "\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_abortion.fit(\n",
    "    x = abortion_train_subset['bert'], \n",
    "    y = abortion_train_subset['labels_encoded'],\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    epochs = 15,\n",
    "    verbose = 2,\n",
    "    batch_size = 32,\n",
    "    class_weight = abortion_train_subset['class_weights'])\n",
    "\n",
    "# NOTES:\n",
    "    # Validation should not be on test data\n",
    "    # models and weights should be topic-specific\n",
    "    \n",
    "pred_test_abortion = model_abortion.predict(x = abortion_test_subset['bert'])\n",
    "\n",
    "standard_metrics(true_labels = abortion_test_subset['labels_text'], \n",
    "                 test_probs = pred_test_abortion,\n",
    "                 label_titles = label_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 95)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 95)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 95)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_11 (BertLayer)       (None, None, 768)    108931396   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, None, 768)    0           bert_layer_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 128)          459264      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 64)           8256        lstm1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 64)           0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 3)            195         dropout_23[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,399,111\n",
      "Trainable params: 6,963,459\n",
      "Non-trainable params: 102,435,652\n",
      "__________________________________________________________________________________________________\n",
      "Train on 316 samples, validate on 79 samples\n",
      "Epoch 1/15\n",
      "316/316 - 39s - loss: 1.2200 - categorical_accuracy: 0.4937 - val_loss: 1.7865 - val_categorical_accuracy: 0.4937\n",
      "Epoch 2/15\n",
      "316/316 - 27s - loss: 1.2587 - categorical_accuracy: 0.4177 - val_loss: 1.5224 - val_categorical_accuracy: 0.5190\n",
      "Epoch 3/15\n",
      "316/316 - 26s - loss: 1.0937 - categorical_accuracy: 0.3070 - val_loss: 1.5601 - val_categorical_accuracy: 0.4937\n",
      "Epoch 4/15\n",
      "316/316 - 26s - loss: 1.1137 - categorical_accuracy: 0.4082 - val_loss: 1.5291 - val_categorical_accuracy: 0.4937\n",
      "Epoch 5/15\n",
      "316/316 - 26s - loss: 0.9970 - categorical_accuracy: 0.4367 - val_loss: 1.5403 - val_categorical_accuracy: 0.4937\n",
      "Epoch 6/15\n",
      "316/316 - 26s - loss: 1.0744 - categorical_accuracy: 0.4114 - val_loss: 1.5837 - val_categorical_accuracy: 0.6329\n",
      "Epoch 7/15\n",
      "316/316 - 26s - loss: 0.9729 - categorical_accuracy: 0.4367 - val_loss: 1.6429 - val_categorical_accuracy: 0.5190\n",
      "Epoch 8/15\n",
      "316/316 - 26s - loss: 1.0761 - categorical_accuracy: 0.4335 - val_loss: 1.5753 - val_categorical_accuracy: 0.5570\n",
      "Epoch 9/15\n",
      "316/316 - 26s - loss: 0.9834 - categorical_accuracy: 0.4778 - val_loss: 1.5306 - val_categorical_accuracy: 0.4304\n",
      "Epoch 10/15\n",
      "316/316 - 26s - loss: 0.8512 - categorical_accuracy: 0.4462 - val_loss: 1.6215 - val_categorical_accuracy: 0.5570\n",
      "Epoch 11/15\n",
      "316/316 - 26s - loss: 0.9158 - categorical_accuracy: 0.4557 - val_loss: 2.3807 - val_categorical_accuracy: 0.5823\n",
      "Epoch 12/15\n",
      "316/316 - 27s - loss: 0.9582 - categorical_accuracy: 0.4367 - val_loss: 1.3834 - val_categorical_accuracy: 0.5063\n",
      "Epoch 13/15\n",
      "316/316 - 27s - loss: 0.9437 - categorical_accuracy: 0.4905 - val_loss: 1.9403 - val_categorical_accuracy: 0.6076\n",
      "Epoch 14/15\n",
      "316/316 - 26s - loss: 0.8369 - categorical_accuracy: 0.4715 - val_loss: 1.7191 - val_categorical_accuracy: 0.5443\n",
      "Epoch 15/15\n",
      "316/316 - 26s - loss: 0.8025 - categorical_accuracy: 0.5095 - val_loss: 2.0836 - val_categorical_accuracy: 0.4684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timspittle/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/timspittle/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 macro score: 0.14582845242743722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     AGAINST       0.00      0.00      0.00        11\n",
      "       FAVOR       0.86      0.05      0.09       123\n",
      "        NONE       0.21      0.97      0.35        35\n",
      "\n",
      "    accuracy                           0.24       169\n",
      "   macro avg       0.36      0.34      0.15       169\n",
      "weighted avg       0.67      0.24      0.14       169\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "model_atheism = bert_lstm_model(max_length_in = max_length, \n",
    "                                bert_fine_tune_layers = 12, \n",
    "                                optimizer = 'adam',\n",
    "                                learning_rate_in = 0.1,\n",
    "                                dropout_rate_in = 0.8)\n",
    "\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_atheism.fit(\n",
    "    x = atheism_train_subset['bert'], \n",
    "    y = atheism_train_subset['labels_encoded'],\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    epochs = 15,\n",
    "    verbose = 2,\n",
    "    batch_size = 32,\n",
    "    class_weight = atheism_train_subset['class_weights'])\n",
    "\n",
    "pred_test_atheism = model_atheism.predict(x = atheism_test_subset['bert'])\n",
    "\n",
    "standard_metrics(true_labels = atheism_test_subset['labels_text'], \n",
    "                 test_probs = pred_test_atheism,\n",
    "                 label_titles = label_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 95)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 95)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 95)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_12 (BertLayer)       (None, None, 768)    108931396   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, None, 768)    0           bert_layer_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 128)          459264      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 64)           8256        lstm1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 64)           0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 3)            195         dropout_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,399,111\n",
      "Trainable params: 6,963,459\n",
      "Non-trainable params: 102,435,652\n",
      "__________________________________________________________________________________________________\n",
      "Train on 551 samples, validate on 138 samples\n",
      "Epoch 1/15\n",
      "551/551 - 59s - loss: 1.2768 - categorical_accuracy: 0.3358 - val_loss: 0.8254 - val_categorical_accuracy: 0.1304\n",
      "Epoch 2/15\n",
      "551/551 - 48s - loss: 1.1854 - categorical_accuracy: 0.2613 - val_loss: 0.8764 - val_categorical_accuracy: 0.1304\n",
      "Epoch 3/15\n",
      "551/551 - 47s - loss: 1.1798 - categorical_accuracy: 0.2595 - val_loss: 0.8559 - val_categorical_accuracy: 0.0725\n",
      "Epoch 4/15\n",
      "551/551 - 46s - loss: 1.1820 - categorical_accuracy: 0.2740 - val_loss: 0.8418 - val_categorical_accuracy: 0.2319\n",
      "Epoch 5/15\n",
      "551/551 - 46s - loss: 1.1605 - categorical_accuracy: 0.3103 - val_loss: 0.9204 - val_categorical_accuracy: 0.1087\n",
      "Epoch 6/15\n",
      "551/551 - 46s - loss: 1.0878 - categorical_accuracy: 0.3920 - val_loss: 0.7677 - val_categorical_accuracy: 0.1884\n",
      "Epoch 7/15\n",
      "551/551 - 47s - loss: 0.9947 - categorical_accuracy: 0.4465 - val_loss: 0.8329 - val_categorical_accuracy: 0.1884\n",
      "Epoch 8/15\n",
      "551/551 - 47s - loss: 0.9185 - categorical_accuracy: 0.4574 - val_loss: 0.8874 - val_categorical_accuracy: 0.1884\n",
      "Epoch 9/15\n",
      "551/551 - 50s - loss: 0.9142 - categorical_accuracy: 0.4791 - val_loss: 0.8371 - val_categorical_accuracy: 0.1884\n",
      "Epoch 10/15\n",
      "551/551 - 49s - loss: 0.7847 - categorical_accuracy: 0.5100 - val_loss: 0.8699 - val_categorical_accuracy: 0.2101\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-9b461969adb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     class_weight = climate_change_train_subset['class_weights'])\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mpred_test_climate_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_climate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclimate_change_test_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "model_climate = bert_lstm_model(max_length_in = max_length, \n",
    "                                bert_fine_tune_layers = 12, \n",
    "                                optimizer = 'adam',\n",
    "                                learning_rate_in = 0.1,\n",
    "                                dropout_rate_in = 0.8)\n",
    "\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_climate.fit(\n",
    "    x = climate_change_train_subset['bert'], \n",
    "    y = climate_change_train_subset['labels_encoded'],\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    epochs = 15,\n",
    "    verbose = 2,\n",
    "    batch_size = 32,\n",
    "    class_weight = climate_change_train_subset['class_weights'])\n",
    "\n",
    "pred_test_climate_change = model_climate.predict(x = climate_change_test_subset['bert'])\n",
    "\n",
    "standard_metrics(true_labels = climate_change_test_subset['labels_text'], \n",
    "                 test_probs = pred_test_climate_change,\n",
    "                 label_titles = label_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feminism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "model_feminism = bert_lstm_model(max_length_in = max_length, \n",
    "                                 bert_fine_tune_layers = 12, \n",
    "                                 optimizer = 'adam',\n",
    "                                 learning_rate_in = 0.1,\n",
    "                                 dropout_rate_in = 0.8)\n",
    "\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_feminism.fit(\n",
    "    x = feminism_train_subset['bert'], \n",
    "    y = feminism_train_subset['labels_encoded'],\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    epochs = 15,\n",
    "    verbose = 2,\n",
    "    batch_size = 32,\n",
    "    class_weight = feminism_train_subset['class_weights'])\n",
    "\n",
    "pred_test_feminism = model_feminism.predict(x = feminism_test_subset['bert'])\n",
    "\n",
    "standard_metrics(true_labels = feminism_test_subset['labels_text'], \n",
    "                 test_probs = pred_test_feminism,\n",
    "                 label_titles = label_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "model_hillary = bert_lstm_model(max_length_in = max_length, \n",
    "                                bert_fine_tune_layers = 12, \n",
    "                                optimizer = 'adam',\n",
    "                                learning_rate_in = 0.1,\n",
    "                                dropout_rate_in = 0.8)\n",
    "\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_hillary.fit(\n",
    "    x = hillary_train_subset['bert'], \n",
    "    y = hillary_train_subset['labels_encoded'],\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    epochs = 15,\n",
    "    verbose = 2,\n",
    "    batch_size = 32,\n",
    "    class_weight = hillary_train_subset['class_weights'])\n",
    "\n",
    "pred_test_hillary = model_hillary.predict(x = hillary_test_subset['bert'])\n",
    "\n",
    "standard_metrics(true_labels = hillary_test_subset['labels_text'], \n",
    "                 test_probs = pred_test_hillary,\n",
    "                 label_titles = label_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of predicted probabilities\n",
    "def class_prob_breakdown(true_labels, test_probs, label_titles):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.title(\"Prob. Dist. - Predicted \" + label_titles[0])\n",
    "    plt.hist([item[0] for item in test_probs])\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.title(\"Prob. Dist. - Predicted \" + label_titles[1])\n",
    "    plt.hist([item[1] for item in test_probs])\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.title(\"Prob. Dist. - Predicted \" + label_titles[2])\n",
    "    plt.hist([item[2] for item in test_probs])\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.title(\"Prob. Dist., by True Label - \" + label_titles[0])\n",
    "    sns.distplot([item[0] for item in test_probs[true_labels==label_titles[0]]], hist = False, label = \"True \" + label_titles[0])\n",
    "    sns.distplot([item[0] for item in test_probs[true_labels==label_titles[1]]], hist = False, label = \"True \" + label_titles[1])\n",
    "    sns.distplot([item[0] for item in test_probs[true_labels==label_titles[2]]], hist = False, label = \"True \" + label_titles[2])\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.title(\"Prob. Dist., by True Label - \" + label_titles[1])\n",
    "    sns.distplot([item[1] for item in test_probs[true_labels==label_titles[0]]], hist = False, label = \"True \" + label_titles[0])\n",
    "    sns.distplot([item[1] for item in test_probs[true_labels==label_titles[1]]], hist = False, label = \"True \" + label_titles[1])\n",
    "    sns.distplot([item[1] for item in test_probs[true_labels==label_titles[2]]], hist = False, label = \"True \" + label_titles[2])\n",
    "    \n",
    "    plt.subplot(2,3,6)\n",
    "    plt.title(\"Prob. Dist., by True Label - \" + label_titles[2])\n",
    "    sns.distplot([item[2] for item in test_probs[true_labels==label_titles[0]]], hist = False, label = \"True \" + label_titles[0])\n",
    "    sns.distplot([item[2] for item in test_probs[true_labels==label_titles[1]]], hist = False, label = \"True \" + label_titles[1])\n",
    "    sns.distplot([item[2] for item in test_probs[true_labels==label_titles[2]]], hist = False, label = \"True \" + label_titles[2])\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
