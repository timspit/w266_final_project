---
title: "Stance Detection in Tweets"
subtitle: "W266 Natural Language Processing - Final Project"
author: "Alex Dessouky & Tim Spittle"
date: "December 7, 2019"
tags: [NLP, BERT, Deep Learning]
abstract: [TBD - Abstract goes here]
output:
  pdf_document:
    fig_caption: no
    number_sections: yes
    toc: no
  md_document:
    variant: markdown
  html_document:
    df_print: paged
    toc: no
bibliography: bibliography.bib
---

```{r packages, include = FALSE}
library(tidyverse)
library(gridExtra)
```

# Introduction

Text  

## Background  

More text   

## Objectives  

More text   

# Related Work  

# Data, Task, & Evaluation  

SemEval 2016 Task 6 [see @mohammad-etal-2016-semeval]

```{r confusion_matrix, echo = FALSE, fig.height = 4, fig.width = 8, fig.align="center", fig.cap="\\label{fig:confusion_matrix}Confusion Matrix"}

label_levels = c("Against", "None", "Favor")
topic_name = "abort"
import_topic = function(topic_name){
  tweet_data = read.csv(file = paste0("./final_outputs/", topic_name, "_tweets_v3.csv"), header = FALSE) %>%
  # Check on why tweets have different index? probably maintain original whereas others are built from scratch
    mutate(V1 = 1:n()-1)
  pred_data = read.csv(file = paste0("./final_outputs/", topic_name, "_preds_v3.csv"), header = FALSE)
  true_data = read.csv(file = paste0("./final_outputs/", topic_name, "_true_v3.csv"), header = FALSE)
  names(pred_data) = c("obs_num", "predicted_label")
  names(true_data) = c("obs_num", "true_label")
  names(tweet_data) = c("obs_num", "tweet")
  
  merged = tweet_data %>%
    merge(pred_data
          , by = "obs_num"
          , all.x = TRUE) %>%
    merge(true_data
          , by = "obs_num"
          , all.x = TRUE) %>%
    mutate(topic = topic_name
           , predicted_label_f = case_when(predicted_label == 0 ~ "Against"
                                         , predicted_label == 1 ~ "None"
                                         , predicted_label == 2 ~ "Favor"
                                         , TRUE ~ NA_character_) %>% factor(levels = label_levels)
           , true_label_f = case_when(true_label == 0 ~ "Against"
                                    , true_label == 1 ~ "None"
                                    , true_label == 2 ~ "Favor"
                                    , TRUE ~ NA_character_) %>% factor(levels = label_levels)
    )
  return(merged)
}

abort = import_topic(topic_name = "abort")
atheism = import_topic(topic_name = "atheism")
clim = import_topic(topic_name = "clim")
hil = import_topic(topic_name = "hil")
fem = import_topic(topic_name = "fem")
all_topics = bind_rows(abort, atheism, clim, hil, fem)

metrics = function(y_true, y_pred){
  confusion_matrix = as.matrix(table(Actual = y_true, Predicted = y_pred))
  n = sum(confusion_matrix) 
  n_classes = nrow(confusion_matrix) 
  correct_byclass = diag(confusion_matrix)  
  instances_byclass = apply(confusion_matrix, 1, sum) 
  predictions_byclass = apply(confusion_matrix, 2, sum) 
  
  precision = correct_byclass / predictions_byclass 
  recall = correct_byclass / instances_byclass 
  f1 = 2 * precision * recall / (precision + recall) 

  classification_report = data.frame("Class" = label_levels
                                    , "Precision" = round(precision * 100, 2)
                                    , "Recall" = round(recall * 100, 2)
                                    , "F1-Score" = round(f1 * 100, 2))
  f1_macro = mean(f1)
  f1_macro_custom = mean(f1[c(1,3)])
  
  metric_list = list()
  metric_list$confusion_matrix = confusion_matrix
  metric_list$classification_report = classification_report
  metric_list$f1_macro = f1_macro
  
  return(metric_list)
}

abort_metrics = metrics(y_true = abort$true_label_f, y_pred = abort$predicted_label_f)
atheism_metrics = metrics(y_true = atheism$true_label_f, y_pred = atheism$predicted_label_f)
clim_metrics = metrics(y_true = clim$true_label_f, y_pred = clim$predicted_label_f)
hil_metrics = metrics(y_true = hil$true_label_f, y_pred = hil$predicted_label_f)
fem_metrics = metrics(y_true = fem$true_label_f, y_pred = fem$predicted_label_f)
all_topics_metrics = metrics(y_true = all_topics$true_label_f, y_pred = all_topics$predicted_label_f)


confusion_plot = ggplot(data =  all_topics %>% group_by(true_label_f, predicted_label_f) %>% summarise(n = n())
       , mapping = aes(x = true_label_f, y = predicted_label_f)) +
  geom_tile(aes(fill = n), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", n)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "green4") +
  theme_bw() + theme(legend.position = "none") +
  labs(x = "True Label", y = "Predicted Label") + 
  scale_y_discrete(limits = rev(label_levels)) +
  scale_x_discrete(limits = rev(label_levels))

grid.arrange(confusion_plot
             , tableGrob(all_topics_metrics$classification_report %>% select(-Class))
             , nrow = 1)
```

\pagebreak

# Methodology  

## Other Work  

BERT [see _\autoref{fig:bert_by_task_fig}_ from @devlin2018bert]

```{r bert_by_task_fig, echo = FALSE, fig.height = 4, fig.width = 4, fig.align="center", fig.cap="\\label{fig:bert_by_task}BERT by Task (Source: @devlin2018bert)"}
knitr::include_graphics(path = "images/bert_bytask.png")
```

\pagebreak

## Ours  

# Results  

```{r f_micro_macro, echo = FALSE}

measure_levels = c("F-micro", "F-macro", "Atheism", "Climate", "Feminism", "Hillary", "Abortion")

f_data = data.frame("measure" = c("F-micro", "F-macro", "Atheism", "Climate", "Feminism", "Hillary", "Abortion") %>% 
                      factor(levels = measure_levels)
                    , "our_model" = c(68.4107211,	59.95842361,	68.88470749,	49.50278923,	53.12994915,	64.32539683,	63.94927536)
                    , "majority_classifer" = c(65.22,	40.092,	42.11,	42.12,	39.1,	36.83,	40.3)
                    ) %>% 
  gather(key = "model", value = "value", -measure)

ggplot(data = f_data) + 
  geom_bar(aes(x = measure, y = value, group = model), stat = "identity", position=position_dodge()) 
# TO DO - color aggregate F scores differently 
```

# Conclusion  

## Discussion  

# Limitations  

## Error Analysis  

## Further Work

# References  