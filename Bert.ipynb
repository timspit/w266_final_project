{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#set working directory\n",
    "os.chdir(\"/Users/alexdessouky/Desktop/MIDS/w266\")\n",
    "\n",
    "#load training data\n",
    "twitter_train = pd.read_excel('./w266_final_project/StanceDataset/train.xlsx')\n",
    "train_x = twitter_train['Tweet']\n",
    "train_y = twitter_train['Stance']\n",
    "\n",
    "#train_x = pd.concat([twitter_train[twitter_train['Stance'] == 'AGAINST'].iloc[0:5,]['Tweet'],\n",
    "#                     twitter_train[twitter_train['Stance'] == 'NONE'].iloc[0:5,]['Tweet'],\n",
    "#                      twitter_train[twitter_train['Stance'] == 'FAVOR'].iloc[0:5,]['Tweet']],\n",
    "#                    axis=0)\n",
    "\n",
    "#train_y = np.array([[1,0,0],[1,0,0],[1,0,0],[1,0,0],[1,0,0],\n",
    "#                  [0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],\n",
    "#                  [0,0,1],[0,0,1],[0,0,1],[0,0,1],[0,0,1]])\n",
    "\n",
    "#load test data\n",
    "twitter_test = pd.read_excel('./w266_final_project/StanceDataset/test.xlsx')\n",
    "test_x = twitter_test['Tweet']\n",
    "test_y = twitter_test['Stance']\n",
    "#test_x = pd.concat([twitter_test[twitter_test['Stance'] == 'AGAINST'].iloc[0:5,]['Tweet'],\n",
    "#                     twitter_test[twitter_test['Stance'] == 'NONE'].iloc[0:5,]['Tweet'],\n",
    "#                      twitter_test[twitter_test['Stance'] == 'FAVOR'].iloc[0:5,]['Tweet']],\n",
    "#                    axis=0)\n",
    "#test_y = np.array([[1,0,0],[1,0,0],[1,0,0],[1,0,0],[1,0,0],\n",
    "#                  [0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],\n",
    "#                  [0,0,1],[0,0,1],[0,0,1],[0,0,1],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the paths to bert & data\n",
    "local_bert_path =   '/Users/alexdessouky/Desktop/MIDS/w266/bert' \n",
    "data_path = '/Users/alexdessouky/Desktop/MIDS/w266/w266_final_project/StanceDataset'  \n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "\n",
    "# make sure that the paths are accessible within the notebook\n",
    "sys.path.insert(0,local_bert_path)\n",
    "sys.path.insert(0,data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1109 13:53:17.303586 140736218923904 deprecation_wrapper.py:119] From /Users/alexdessouky/Desktop/MIDS/w266/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "import run_classifier_with_tfhub\n",
    "\n",
    "# Tensorflow hub path to BERT module of choice\n",
    "bert_url = \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\"\n",
    "\n",
    "# Define maximal length of input 'sentences' (post tokenization).\n",
    "max_length = 83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 13:53:20.519495 140736218923904 deprecation_wrapper.py:119] From /Users/alexdessouky/Desktop/MIDS/w266/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(bert_url)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tokens surrounded by the [CLS] and [SEP] tokens\n",
    "train_tokens = train_x.apply(lambda x: ['[CLS]'] + tokenizer.tokenize(x) + ['[SEP]'])\n",
    "test_tokens = test_x.apply(lambda x: ['[CLS]'] + tokenizer.tokenize(x) + ['[SEP]'])\n",
    "\n",
    "#mask ids (mask out the paddings)\n",
    "train_mask_ids = train_tokens.apply(lambda x: len(x)*[1])\n",
    "test_mask_ids = test_tokens.apply(lambda x: len(x)*[1])\n",
    "\n",
    "train_mask_ids = train_mask_ids.apply(lambda x: np.array(x + (max_length - len(x)) * [0]) if len(x) < max_length else \n",
    "                                      np.array(x)).tolist()\n",
    "test_mask_ids = test_mask_ids.apply(lambda x: np.array(x + (max_length - len(x)) * [0]) if len(x) < max_length else \n",
    "                                    np.array(x)).tolist()\n",
    "\n",
    "#add padding to tokens\n",
    "train_tokens = train_tokens.apply(lambda x: x + (max_length - len(x)) * ['[PAD]'] if len(x) < max_length else x)\n",
    "test_tokens = test_tokens.apply(lambda x: x + (max_length - len(x)) * ['[PAD]'] if len(x) < max_length else x)\n",
    "\n",
    "#test/train sequence vectors\n",
    "train_sequenceids = train_tokens.apply(lambda x: np.array(max_length*[0])).tolist()\n",
    "test_sequenceids = test_tokens.apply(lambda x: np.array(max_length*[0])).tolist()\n",
    "\n",
    "#convert tokens to sentence ids\n",
    "train_sentenceids = train_tokens.apply(lambda x: np.array(tokenizer.convert_tokens_to_ids(x))).tolist()\n",
    "test_sentenceids = test_tokens.apply(lambda x: np.array(tokenizer.convert_tokens_to_ids(x))).tolist()\n",
    "\n",
    "#bert features\n",
    "bert_train = [np.array(train_sentenceids),np.array(train_mask_ids),np.array(train_sequenceids)]\n",
    "bert_test = [np.array(test_sentenceids),np.array(test_mask_ids),np.array(test_sequenceids)]\n",
    "\n",
    "#labels\n",
    "stance_labels_train = np.array(twitter_train['Stance'].apply(lambda x: \n",
    "                                                                    2 if x == \"FAVOR\" else \n",
    "                                                                    (1 if x == \"NONE\" else 0)))\n",
    "\n",
    "stance_labels_test = np.array(twitter_test['Stance'].apply(lambda x: \n",
    "                                                                    2 if x == \"FAVOR\" else \n",
    "                                                                    (1 if x == \"NONE\" else 0)))\n",
    "\n",
    "            \n",
    "\n",
    "#PREP LABELS FOR NN\n",
    "train_y = np.zeros(shape = (stance_labels_train.shape[0],3))\n",
    "train_y[stance_labels_train == 0,0] = 1\n",
    "train_y[stance_labels_train == 1,1] = 1\n",
    "train_y[stance_labels_train == 2,2] = 1\n",
    "\n",
    "test_y = np.zeros(shape = (stance_labels_test.shape[0],3))\n",
    "test_y[stance_labels_test == 0,0] = 1\n",
    "test_y[stance_labels_test == 1,1] = 1\n",
    "test_y[stance_labels_test == 2,2] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer to create Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            bert_url,\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        trainable_vars = self.bert.variables\n",
    "        \n",
    "        # Remove unused layers\n",
    "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "        \n",
    "        # Select how many layers to fine tune\n",
    "        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "        \n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "        \n",
    "        # Add non-trainable weights\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        \n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "            \"pooled_output\"\n",
    "        ]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model(max_input_length, train_layers, optimizer = tf.keras.optimizers.Adam(learning_rate=1)):\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length,), name=\"segment_ids\")\n",
    "    \n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_sequence = BertLayer(n_fine_tune_layers=train_layers)(bert_inputs)\n",
    "    \n",
    "    dropout1= tf.keras.layers.Dropout(rate=0.5)(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(dropout1)\n",
    "    \n",
    "    dropout2 = tf.keras.layers.Dropout(rate=0.5)(dense)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(3, activation='softmax', name='classification')(dropout2)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics = ['categorical_accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 13:53:36.830524 140736218923904 deprecation.py:506] From /Users/alexdessouky/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 83)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 83)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 83)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, 768)          108931396   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 3)            771         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,129,031\n",
      "Trainable params: 6,693,379\n",
      "Non-trainable params: 102,435,652\n",
      "__________________________________________________________________________________________________\n",
      "Train on 2914 samples, validate on 1956 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 13:53:38.921864 140736218923904 deprecation.py:323] From /Users/alexdessouky/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "2914/2914 - 762s - loss: 1.1845 - categorical_accuracy: 0.4073 - val_loss: 0.9861 - val_categorical_accuracy: 0.5235\n",
      "Epoch 2/6\n",
      "2914/2914 - 746s - loss: 0.9000 - categorical_accuracy: 0.5748 - val_loss: 1.1017 - val_categorical_accuracy: 0.4514\n",
      "Epoch 3/6\n",
      "2914/2914 - 749s - loss: 0.7449 - categorical_accuracy: 0.6719 - val_loss: 1.0183 - val_categorical_accuracy: 0.4586\n",
      "Epoch 4/6\n",
      "2914/2914 - 763s - loss: 0.5891 - categorical_accuracy: 0.7371 - val_loss: 1.3179 - val_categorical_accuracy: 0.4167\n",
      "Epoch 5/6\n",
      "2914/2914 - 773s - loss: 0.4969 - categorical_accuracy: 0.7931 - val_loss: 1.5346 - val_categorical_accuracy: 0.4990\n",
      "Epoch 6/6\n",
      "2914/2914 - 774s - loss: 0.3097 - categorical_accuracy: 0.8802 - val_loss: 1.4413 - val_categorical_accuracy: 0.5440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3881f550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Start session\n",
    "\n",
    "compute_class = compute_class_weight('balanced', np.unique(stance_labels_test), stance_labels_test)\n",
    "weights = {0: compute_class[0], 1:compute_class[1], 2:compute_class[2]}\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "model = bert_model(max_length + 1, train_layers=12, optimizer = 'adam')\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model.fit(\n",
    "    bert_train, \n",
    "    train_y,\n",
    "    validation_data=[bert_test, test_y],\n",
    "    epochs=6,\n",
    "    verbose=2,\n",
    "    batch_size=32,\n",
    "    class_weight = weights)#,\n",
    "    #callbacks=[tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.predict(bert_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_plot(confusion_matrix, target_names):\n",
    "    # Plot confusion matrix (via imshow)\n",
    "    plt.imshow(confusion_matrix, interpolation = \"nearest\", cmap = plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Loop through each value of the matrix to add data labels\n",
    "    width, height = confusion_matrix.shape\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate(str(confusion_matrix[x][y]), xy = (y, x), \n",
    "                        horizontalalignment = \"center\",\n",
    "                        verticalalignment = \"center\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    \n",
    "def metrics(true_labels, test_probs):\n",
    "    \n",
    "    #find predicted labels\n",
    "    test_predicts = np.argmax(test_probs, axis = 1)\n",
    "    \n",
    "    #calculate f1 score\n",
    "    f1 = f1_score(true_labels, test_predicts, average = 'macro')\n",
    "    \n",
    "    print(\"F1 macro score:\", f1)\n",
    "    \n",
    "    print(classification_report(y_true = true_labels, \n",
    "                                        y_pred = test_predicts,\n",
    "                                        target_names = ['Against', 'None', 'Favor']))\n",
    "    \n",
    "    confuse = confusion_matrix(y_true = true_labels, y_pred = test_predicts)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    confusion_plot(confuse, ['Against', 'None', 'Favor'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 macro score: 0.5288508863874488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Against       0.71      0.53      0.61      1014\n",
      "        None       0.39      0.68      0.50       490\n",
      "       Favor       0.55      0.42      0.48       452\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      1956\n",
      "   macro avg       0.55      0.55      0.53      1956\n",
      "weighted avg       0.59      0.54      0.55      1956\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics(stance_labels_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
